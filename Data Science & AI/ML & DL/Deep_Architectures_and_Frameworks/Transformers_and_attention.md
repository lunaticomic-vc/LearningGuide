# Transformers_and_attention

## 1. Activate Prior Knowledge
- Какво знаете за традиционните модели за обработка на последователности, като RNN и LSTM? Какви са техните ограничения?
- Как бихте описали ролята на вниманието (attention) в човешкото възприятие и как това може да се приложи в изкуствения интелект?
- Какво очаквате да научите за трансформърите и тяхната роля в съвременните AI системи?

## 2. Overview
Трансформърите са архитектура за моделиране на последователности, която революционизира обработката на естествен език и други задачи с последователни данни. Те заменят традиционните рекурентни и конволюционни модели с механизъм, наречен "внимание" (attention), който позволява на модела да се фокусира върху различни части от входа по време на обработката.

В по-широк контекст, трансформърите са основата на много съвременни AI системи, включително GPT, BERT и други големи езикови модели. Те са ключови за задачи като превод, обобщаване, въпроси и отговори, и дори извън езиковата сфера – в компютърното зрение и биоинформатиката.

Значението на трансформърите идва от тяхната способност да обработват дълги зависимости в данните ефективно и паралелно, което значително ускорява обучението и подобрява качеството на резултатите. Това ги прави незаменими в съвременната софтуерна инженерия и изследвания в AI.

## 3. Key Concepts
- **Transformer Architecture** – Модел, базиран на слоеве от внимание и напредващи невронни мрежи, който обработва цялата входна последователност паралелно, вместо стъпка по стъпка.
- **Self-Attention** – Механизъм, при който всеки елемент от входа се сравнява с всички останали, за да се определи кои части са най-важни за текущата задача. Може да се представи като "вътрешен диалог" между думите в изречението.
- **Multi-Head Attention** – Разширение на self-attention, което позволява на модела да се фокусира върху различни аспекти на входа едновременно, подобно на няколко наблюдатели, гледащи от различни ъгли.
- **Positional Encoding** – Тъй като трансформърите не обработват данните последователно, тази техника добавя информация за позицията на думите в изречението, за да запази реда.
- **Encoder-Decoder Structure** – Класическа архитектура на трансформъра, където енкодерът обработва входа, а декодерът генерира изхода, използвайки вниманието и контекста.

## 4. Step-by-step Learning Path
1. **Фокус:** Разберете основите на self-attention.
   - **Задача:** Изчислете ръчно self-attention върху малък пример с 3 думи и фиксирани вектори.
   - **Въпроси:** Какво представлява вниманието? Защо е важно да се сравняват всички елементи в последователността?
   
2. **Фокус:** Изучете multi-head attention и неговата роля.
   - **Задача:** Имплементирайте multi-head attention с 2 глави върху примерни данни с Python и NumPy.
   - **Въпроси:** Как multi-head attention подобрява представянето спрямо единичната глава?

3. **Фокус:** Разберете positional encoding и защо е необходим.
   - **Задача:** Напишете функция, която генерира позиционни кодировки за дадена дължина на последователността.
   - **Въпроси:** Какво би се случило, ако не използваме позиционна информация?

4. **Фокус:** Запознайте се с цялостната архитектура на трансформър – енкодер и декодер.
   - **Задача:** Прегледайте и анализирайте код на отворен трансформър модел (например Hugging Face).
   - **Въпроси:** Как енкодерът и декодерът си взаимодействат? Каква е ролята на вниманието в декодера?

5. **Фокус:** Практическо приложение – обучение на малък трансформър за задача за превод или текстова класификация.
   - **Задача:** Използвайте библиотека като PyTorch или TensorFlow, за да обучите трансформър на малък набор от данни.
   - **Въпроси:** Какви са предизвикателствата при обучението? Как се измерва успехът?

## 5. Examples
- **Пример 1: Self-attention изчисление**
```python
import numpy as np

# Вектори за 3 думи (3 x 4)
X = np.array([[1,0,1,0],
              [0,2,0,2],
              [1,1,1,1]])

# Ключове, заявки и стойности (за опростяване са равни на X)
Q = K = V = X

# Изчисляване на вниманието
scores = np.dot(Q, K.T) / np.sqrt(Q.shape[1])
weights = np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)
output = np.dot(weights, V)

print("Output на self-attention:\n", output)
```

- **Пример 2: Използване на Hugging Face трансформър за класификация**
```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
result = classifier("Трансформърите променят начина, по който машините разбират езика.")
print(result)
```

- **Пример 3: Позиционно кодиране (синусоидално)**
```python
import numpy as np

def positional_encoding(seq_len, d_model):
    PE = np.zeros((seq_len, d_model))
    for pos in range(seq_len):
        for i in range(0, d_model, 2):
            PE[pos, i] = np.sin(pos / (10000 ** ((2 * i)/d_model)))
            if i+1 < d_model:
                PE[pos, i+1] = np.cos(pos / (10000 ** ((2 * (i+1))/d_model)))
    return PE

print(positional_encoding(5, 6))
```

## 6. Common Pitfalls
- **Игнориране на позиционната информация** – без positional encoding трансформърът губи контекста на реда, което води до лошо представяне.
- **Неправилно мащабиране на вниманието** – забравата да се раздели скаларното произведение на корен квадратен от размерността води до нестабилно обучение.
- **Прекалено малък брой глави в multi-head attention** – ограничава способността на модела да улавя различни аспекти на данните.
- **Липса на маскиране при декодера** – при генериране на текст трябва да се маскират бъдещите позиции, за да не се използва информация от бъдещето.
- **Прекомерно доверие в трансформърите без разбиране на данните** – трансформърите са мощни, но не решават автоматично всички проблеми, особено при недостатъчни или шумни данни.

## 7. Short Retrieval Quiz
1. Какво представлява self-attention и защо е важно?
2. Какво е multi-head attention и какво добавя към модела?
3. Защо трансформърите използват positional encoding?
4. Каква е ролята на енкодера и декодера в трансформър архитектурата?
5. Какво може да се случи, ако не се използва маскиране в декодера?
6. Кое е основното предимство на трансформърите пред RNN?
7. Как се изчисляват тежестите на вниманието?

## 8. Quick Recap
- Трансформърите използват механизма self-attention за паралелна обработка на последователности.
- Multi-head attention позволява на модела да разглежда данните от различни перспективи едновременно.
- Positional encoding добавя информация за реда на елементите, която трансформърите сами не могат да извлекат.
- Архитектурата енкодер-декодер е основна за задачи като машинен превод.
- Правилната имплементация на вниманието и маскирането е критична за успеха.
- Трансформърите значително подобряват скоростта и качеството на моделиране спрямо предишни подходи.
- Практическото обучение изисква разбиране на архитектурата и внимателно управление на данните.

## 9. Spaced Review Plan

| Време след учене | Прегледна задача                                      |
|------------------|------------------------------------------------------|
| 1 ден            | Обяснете self-attention и multi-head attention с примери. |
| 3 дни            | Напишете кратък код за positional encoding.          |
| 1 седмица        | Анализирайте архитектурата на трансформър и ролята на енкодер/декодер. |
| 1 месец          | Обсъдете типични грешки при имплементация и как да ги избегнете. |