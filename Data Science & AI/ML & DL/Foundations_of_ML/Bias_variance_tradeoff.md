# Bias_variance_tradeoff

## 1. Activate Prior Knowledge
- Какво разбирате под термина "преобучаване" (overfitting) и "недообучаване" (underfitting) в контекста на машинното обучение?
- Как мислите, че сложността на модела влияе върху неговата способност да обобщава нови данни?
- Какви компромиси бихте направили при избора на модел за софтуерна система, която трябва да бъде както точна, така и стабилна?

## 2. Overview
Bias-variance tradeoff е фундаментален концепт в машинното обучение и статистиката, който описва баланса между две основни грешки при моделирането: bias (систематична грешка) и variance (вариабилност). Целта е да се намери оптималната точка, при която моделът е достатъчно сложен, за да улови важните зависимости в данните, но не толкова сложен, че да започне да се адаптира към шум или случайни отклонения.

В по-широк контекст, този tradeoff е ключов за изграждането на надеждни AI системи и софтуерни решения, които трябва да работят добре не само върху обучаващите данни, но и върху нови, невиждани примери. Разбирането и управлението на bias и variance помага да се избегнат често срещани проблеми като преобучаване и недообучаване, които могат да компрометират качеството на модела.

Този баланс е също така важен при избора на алгоритми, настройката на хиперпараметри и оценката на производителността на системата. Затова е критично за професионалистите в областта на AI и софтуерната инженерия да имат дълбоко и практично разбиране на bias-variance tradeoff.

## 3. Key Concepts
- **Bias (Систематична грешка)** – Това е разликата между средната прогноза на модела и истинската стойност. Висок bias означава, че моделът е твърде опростен и не улавя важните зависимости (недообучаване). Мислете за bias като за "предразсъдък" на модела.
- **Variance (Вариабилност)** – Това е степента, до която прогнозите на модела варират при различни обучаващи набори. Висок variance означава, че моделът е твърде чувствителен към шум в данните (преобучаване). Представете си variance като "нестабилност" на модела.
- **Overfitting (Преобучаване)** – Случва се, когато моделът има нисък bias, но много висок variance, т.е. той се адаптира прекалено към обучаващите данни, включително и към шума.
- **Underfitting (Недообучаване)** – Случва се, когато моделът има висок bias и нисък variance, т.е. не успява да улови основните зависимости в данните.
- **Generalization (Обобщаване)** – Способността на модела да прави точни прогнози върху нови, невиждани данни. Целта е да се минимизира общата грешка, която е комбинация от bias и variance.
- **Model Complexity (Сложност на модела)** – Колко гъвкав е моделът да се адаптира към данните. По-висока сложност обикновено намалява bias, но увеличава variance.

## 4. Step-by-step Learning Path
1. **Фокус:** Разберете дефинициите на bias и variance.  
   **Задача:** Напишете кратко резюме с ваши думи какво е bias и variance.  
   **Въпроси за припомняне:** Какво представлява bias? Какво представлява variance?

2. **Фокус:** Изследвайте примери за overfitting и underfitting.  
   **Задача:** Създайте прост модел (например линейна регресия) и го обучете върху малък набор от данни, след което увеличете сложността (например добавете полиномиални функции). Наблюдавайте поведението на грешката върху обучаващия и тестовия набор.  
   **Въпроси за припомняне:** Как се променя грешката при увеличаване на сложността? Как разпознавате overfitting?

3. **Фокус:** Анализирайте как хиперпараметрите влияят на bias и variance.  
   **Задача:** Използвайте библиотека за машинно обучение (например scikit-learn) и експериментирайте с параметри като дълбочина на дървото или броя на съседите в k-NN.  
   **Въпроси за припомняне:** Как промяната на хиперпараметрите влияе на bias и variance? Как да изберете оптимални параметри?

4. **Фокус:** Прилагайте техники за контрол на bias-variance tradeoff.  
   **Задача:** Имплементирайте крос-валидация и регуляризация (L1/L2) върху реален набор от данни.  
   **Въпроси за припомняне:** Как регуляризацията влияе на bias и variance? Как крос-валидацията помага при избора на модел?

5. **Фокус:** Разгледайте случаи от реалния свят и системи, където tradeoff е критичен.  
   **Задача:** Анализирайте статия или проект, в който е обсъден bias-variance tradeoff и опишете как е решен.  
   **Въпроси за припомняне:** Защо е важно да се балансира bias и variance в реални приложения?

## 5. Examples
### Пример 1: Линейна регресия срещу полиномиална регресия
```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Генериране на данни
np.random.seed(0)
X = np.sort(np.random.rand(20, 1) * 10, axis=0)
y = np.sin(X).ravel() + np.random.normal(0, 0.3, X.shape[0])

# Линейна регресия (висок bias, нисък variance)
model_linear = LinearRegression()
model_linear.fit(X, y)

# Полиномиална регресия степен 10 (нисък bias, висок variance)
model_poly = make_pipeline(PolynomialFeatures(10), LinearRegression())
model_poly.fit(X, y)

X_test = np.linspace(0, 10, 100).reshape(-1, 1)
plt.scatter(X, y, color='black')
plt.plot(X_test, model_linear.predict(X_test), label='Linear Regression')
plt.plot(X_test, model_poly.predict(X_test), label='Polynomial Degree 10')
plt.legend()
plt.show()
```
*Обяснение:* Линейният модел има висок bias и не успява да улови сложната форма, докато полиномиалният модел се адаптира прекалено към обучаващите данни (висок variance).

### Пример 2: Регуляризация за контрол на overfitting
```python
from sklearn.linear_model import Ridge
ridge = Ridge(alpha=1.0)  # Регуляризация L2
ridge.fit(X, y)
print("Ridge Regression Coefficients:", ridge.coef_)
```
*Обяснение:* Регуляризацията намалява variance, като ограничава сложността на модела, което помага да се избегне преобучаване.

## 6. Common Pitfalls
- **Игнориране на tradeoff:** Опитвате се да минимизирате само bias или само variance, което води до suboptimal модели.
- **Прекалено сложни модели без контрол:** Използване на сложни модели без регуляризация или крос-валидация често води до преобучаване.
- **Недостатъчно данни:** Малки обучаващи набори увеличават variance и затрудняват правилната оценка на модела.
- **Неправилна оценка на производителността:** Използване на обучаващите данни за тестване води до подвеждащи резултати.
- **Пренебрегване на шума в данните:** Модели, които се опитват да обяснят шума, имат висок variance.

## 7. Short Retrieval Quiz
1. Какво е bias в контекста на машинното обучение?
2. Какво означава variance и как влияе върху модела?
3. Какво е преобучаване и как се свързва с bias и variance?
4. Как регуляризацията помага при bias-variance tradeoff?
5. Какво е underfitting?
6. Защо е важно да се използва крос-валидация?
7. Как сложността на модела влияе на bias и variance?

## 8. Quick Recap
- Bias е систематична грешка, която показва колко далеч е моделът от истинската функция.
- Variance измерва чувствителността на модела към различни обучаващи набори.
- Преобучаването е резултат от нисък bias и висок variance.
- Недообучаването е резултат от висок bias и нисък variance.
- Целта е да се намери баланс, който минимизира общата грешка.
- Регуляризацията и крос-валидацията са ключови техники за контрол на tradeoff-а.
- Разбирането на bias-variance tradeoff е критично за изграждането на надеждни AI системи.

## 9. Spaced Review Plan

| Време след изучаване | Промпт за преглед                                      |
|----------------------|-------------------------------------------------------|
| 1 ден                | Обяснете с ваши думи какво е bias и variance.         |
| 3 дни                | Дайте пример за преобучаване и недообучаване.          |
| 1 седмица            | Опишете как регуляризацията влияе на bias и variance.  |
| 1 месец              | Приложете bias-variance tradeoff върху реален проект.  |