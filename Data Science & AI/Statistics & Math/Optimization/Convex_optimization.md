# Convex_optimization

## 1. Activate Prior Knowledge
- Какво представлява оптимизацията и къде се използва в софтуерното инженерство и изкуствения интелект?
- Какво знаете за функциите и техните графики – как бихте разпознали „добра“ функция за оптимизация?
- Можете ли да си представите какво означава „глобален минимум“ спрямо „локален минимум“ и защо това е важно?

## 2. Overview
Оптимизацията е процесът на намиране на най-добро решение спрямо дадени критерии и ограничения. В контекста на изкуствения интелект и софтуерното инженерство, тя е ключова за обучение на модели, разпределение на ресурси, планиране и вземане на решения. Конвексната оптимизация е специален клас оптимизационни задачи, при които целевата функция и ограниченията са конвексни, което гарантира, че локалният минимум е и глобален.

Това свойство прави конвексната оптимизация изключително ценна, тъй като позволява ефективни и надеждни алгоритми за решаване, дори при големи и сложни системи. Тя се използва в машинното обучение (например при линейна регресия, SVM), контролни системи, икономика и много други области. Разбирането на конвексната оптимизация дава на инженера мощен инструмент за моделиране и решаване на реални проблеми.

## 3. Key Concepts
- **Конвексна функция** – функция, при която всеки отсечен сегмент между две точки на графиката лежи над или върху графиката. Мислете за „усмихната“ форма, която няма „бразди“ или „вдлъбнатини“.
- **Конвексен набор** – множество, в което за всяка двойка точки, целият отсечен сегмент между тях също принадлежи на множеството. Представете си плоска повърхност без „дупки“ или „издатини“.
- **Глобален минимум** – точката, в която функцията достига най-ниската си стойност в целия набор. При конвексни функции локалният минимум е винаги глобален.
- **Локален минимум** – точка, където функцията е по-ниска от всички близки точки, но не е задължително да е най-ниската в целия набор.
- **Лагранжови множители** – метод за решаване на оптимизационни задачи с ограничения чрез въвеждане на допълнителни променливи.
- **Градиентен метод** – итеративен алгоритъм, който използва градиента (производната) на функцията, за да се движи към минимум.
- **Първичен и двойствен проблем** – концепция, при която всяка оптимизационна задача може да бъде разгледана от две гледни точки, което често улеснява решаването.

## 4. Step-by-step Learning Path
1. **Фокус:** Разбиране на основите на конвексността.  
   **Задача:** Нарисувайте графики на конвексни и неконвексни функции и идентифицирайте разликите.  
   **Въпроси:** Какво отличава конвексната функция от неконвексната? Защо конвексността е важна за оптимизацията?

2. **Фокус:** Формулиране на конвексни оптимизационни задачи.  
   **Задача:** Запишете пример за задача с конвексна целева функция и линейни ограничения.  
   **Въпроси:** Какви са типичните ограничения в конвексната оптимизация? Какво означава „линейно ограничение“?

3. **Фокус:** Изучаване на градиентния метод и неговите вариации.  
   **Задача:** Имплементирайте прост градиентен спуск за минимизиране на квадратична функция.  
   **Въпроси:** Как градиентът насочва стъпките към минимума? Каква е ролята на размера на стъпката?

4. **Фокус:** Разбиране на Лагранжовите множители и двойствените задачи.  
   **Задача:** Решете примерна задача с едно ограничение, използвайки Лагранжови множители.  
   **Въпроси:** Какво представлява двойственият проблем? Как Лагранжовите множители помагат при ограничения?

5. **Фокус:** Прилагане на конвексна оптимизация в машинното обучение.  
   **Задача:** Използвайте библиотека (например CVXPY) за решаване на задача на линейна регресия с L2-регуларизация.  
   **Въпроси:** Как конвексната оптимизация подобрява обучението на модели? Защо L2-регуларизацията е конвексна?

## 5. Examples
- **Линейна регресия с L2-регуларизация (Ridge Regression):**  
  Целева функция: минимизиране на сумата от квадрати на грешките плюс регуляризационен член.  
  ```python
  import cvxpy as cp
  import numpy as np

  X = np.array([[1, 2], [3, 4], [5, 6]])
  y = np.array([1, 2, 3])
  w = cp.Variable(2)
  lambda_reg = 0.1

  objective = cp.Minimize(cp.sum_squares(X @ w - y) + lambda_reg * cp.norm(w, 2)**2)
  problem = cp.Problem(objective)
  problem.solve()

  print("Оптимални тегла:", w.value)
  ```

- **Оптимизация на портфейл:**  
  Минимизиране на риска (варианс) при дадена очаквана възвръщаемост, с ограничения за сума на теглата.  
  ```python
  # Примерен код с CVXPY за минимизиране на варианс с линейни ограничения
  ```

- **Поддръжка на векторни машини (SVM):**  
  Решаване на конвексна задача за максимизиране на марж с линейни ограничения.

## 6. Common Pitfalls
- **Неправилно формулиране на задачата:** Оптимизационната функция или ограниченията не са конвексни, което води до неефективни или грешни решения.  
  *Как да избегнем:* Винаги проверявайте конвексността на функцията и ограниченията.

- **Избор на неподходящи параметри за алгоритмите:** Например твърде голяма стъпка при градиентния спуск може да доведе до нестабилност.  
  *Как да избегнем:* Използвайте адаптивни методи или тествайте различни стойности.

- **Игнориране на двойствения проблем:** Пропускане на възможността за по-лесно решаване чрез двойствена задача.  
  *Как да избегнем:* Научете се да формулирате и двата проблема и сравнявайте.

- **Локални минимуми при неконвексни функции:** Опит за прилагане на конвексни методи върху неконвексни задачи.  
  *Как да избегнем:* Уверете се, че задачата е конвексна или използвайте други техники.

## 7. Short Retrieval Quiz
1. Какво означава, че функция е конвексна?  
2. Защо локалният минимум при конвексна функция е и глобален?  
3. Каква е ролята на Лагранжовите множители?  
4. Как градиентният метод намира минимум?  
5. Какво представлява двойственият проблем?  
6. Къде в машинното обучение се използва конвексната оптимизация?  
7. Какво е типично ограничение в конвексната оптимизация?

## 8. Quick Recap
- Конвексната оптимизация гарантира, че локалният минимум е глобален, което улеснява решаването.  
- Конвексните функции и множества имат специфична геометрия, която позволява ефективни алгоритми.  
- Градиентният метод е основен инструмент за намиране на минимум при диференцируеми функции.  
- Лагранжовите множители позволяват решаване на задачи с ограничения.  
- Двойственият проблем често предоставя по-лесен или по-интуитивен подход към оптимизацията.  
- Конвексната оптимизация е широко приложима в машинното обучение и инженерството.  
- Винаги проверявайте конвексността на задачата преди да изберете метод за решаване.

## 9. Spaced Review Plan

| Време след учене | Преговорна задача                                   |
|------------------|----------------------------------------------------|
| 1 ден            | Обяснете с прости думи какво е конвексна функция. |
| 3 дни            | Решете малка задача с градиентен спуск.            |
| 1 седмица        | Формулирайте и решете задача с Лагранжови множители.|
| 1 месец          | Прегледайте и имплементирайте пример с CVXPY.     |