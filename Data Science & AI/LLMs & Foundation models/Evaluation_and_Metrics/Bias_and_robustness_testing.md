# Bias_and_robustness_testing

## 1. Activate Prior Knowledge
- Какво разбирате под „пристрастие“ (bias) в контекста на изкуствения интелект и софтуерните системи?
- Защо е важно една система да бъде „робустна“ (robust) спрямо различни входни данни и условия?
- Можете ли да дадете пример за ситуация, в която липсата на тестване за пристрастия или робустност е довела до проблем в реална система?

## 2. Overview
Bias and robustness testing са ключови компоненти в разработката и оценката на AI системи и софтуер. Тестването за пристрастия цели да открие и минимизира нежелани отклонения, които могат да доведат до несправедливи, неточни или дискриминационни резултати. Това е особено важно в системи, които влияят върху хора – като кредитни оценки, медицински диагнози или системи за подбор на персонал.

Робустността на една система се отнася до нейната способност да функционира правилно при различни, често непредвидени условия. Това включва устойчивост на шум, промени в данните, атаки или грешки в изпълнението. В контекста на AI, робустността гарантира, че моделът няма да се срине или да даде некоректни резултати при леко отклонение от обучителните данни.

Тези две области са тясно свързани: системи с пристрастия често са и по-малко робустни, тъй като пристрастията могат да се проявят като уязвимости при нови или различни входни данни. Затова интегрирането на bias и robustness testing в цикъла на разработка е критично за създаване на надеждни и етични AI решения.

## 3. Key Concepts
- **Bias (Пристрастие)** – систематична грешка или отклонение в резултатите на модел, която води до несправедливо третиране на определени групи или случаи. Може да се сравни с „цветни очила“, които изкривяват реалността.
- **Robustness (Робустност)** – способността на система да поддържа стабилна и коректна работа при различни условия, включително шум, непълни или нетипични данни. Представете си го като „амортисьор“, който поема удари и не позволява системата да се повреди.
- **Fairness (Справедливост)** – концепция, свързана с липсата на пристрастия, гарантираща, че системата третира всички групи равноправно.
- **Adversarial Testing (Адвърсариално тестване)** – метод за проверка на робустността чрез умишлено въвеждане на „злонамерени“ или предизвикателни входни данни.
- **Data Distribution Shift (Промяна в разпределението на данните)** – ситуация, при която новите входни данни се различават значително от тези, използвани при обучението, което може да разкрие липси в робустността.
- **Mitigation Strategies (Стратегии за смекчаване)** – техники за намаляване на пристрастия и подобряване на робустността, като баланс на данните, регуляризация и adversarial training.

## 4. Step-by-step Learning Path
1. **Фокус:** Разбиране на видовете пристрастия в AI.
   - **Практическа задача:** Изследвайте публичен набор от данни (например за кредитни решения) и идентифицирайте потенциални източници на пристрастия.
   - **Въпроси за припомняне:** Какво е систематично пристрастие? Кои групи могат да бъдат засегнати?

2. **Фокус:** Основи на робустността и защо е важна.
   - **Практическа задача:** Създайте прост ML модел и тествайте представянето му при добавяне на шум към входните данни.
   - **Въпроси за припомняне:** Какво означава робустност? Как шумът влияе на модела?

3. **Фокус:** Методи за тестване на пристрастия.
   - **Практическа задача:** Използвайте метрики като disparate impact или equal opportunity difference за оценка на пристрастия в модел.
   - **Въпроси за припомняне:** Какви метрики измерват справедливост? Какво показва disparate impact?

4. **Фокус:** Адвърсариално тестване за робустност.
   - **Практическа задача:** Генерирайте adversarial примери за вашия модел с помощта на библиотека като CleverHans или Foolbox.
   - **Въпроси за припомняне:** Какво е adversarial пример? Защо тестването с такива примери е важно?

5. **Фокус:** Стратегии за смекчаване на пристрастия и подобряване на робустността.
   - **Практическа задача:** Прилагайте техники като oversampling, regularization или adversarial training и сравнете резултатите.
   - **Въпроси за припомняне:** Какви са основните подходи за намаляване на пристрастия? Как adversarial training подобрява робустността?

## 5. Examples

### Пример 1: Откриване на пристрастия в модел за кредитно оценяване
```python
import pandas as pd
from sklearn.metrics import confusion_matrix

# Зареждаме данни с пол и доход
data = pd.read_csv('credit_data.csv')
model_predictions = ...  # предположим, че имаме предсказания

# Изчисляваме false positive rate по пол
fp_male = sum((model_predictions[data['gender']=='male'] == 1) & (data['actual']==0))
fp_female = sum((model_predictions[data['gender']=='female'] == 1) & (data['actual']==0))

print(f"False Positive Rate Male: {fp_male}")
print(f"False Positive Rate Female: {fp_female}")
```
Тук се търси дали моделът дискриминира по пол.

### Пример 2: Тестване на робустност с шум
```python
import numpy as np

def add_noise(X, noise_level=0.1):
    noise = np.random.normal(0, noise_level, X.shape)
    return X + noise

X_noisy = add_noise(X_test)
predictions_noisy = model.predict(X_noisy)

print("Accuracy on noisy data:", accuracy_score(y_test, predictions_noisy))
```
Тестът показва колко стабилен е моделът при леко замърсяване на входа.

### Пример 3: Адвърсариално тестване (концептуален пример)
```python
from cleverhans.attacks import FastGradientMethod

fgsm = FastGradientMethod(model, sess=sess)
adv_x = fgsm.generate(x_input, eps=0.1)
adv_preds = model.predict(adv_x)
```
Тук се създават специално изчислени примери, които целят да объркат модела.

## 6. Common Pitfalls
- **Игнориране на пристрастия в данните:** Много инженери третират данните като „обективни“, без да проверят за скрити пристрастия.
- **Тестване само на стандартни метрики:** Оценката само по точност или F1-score може да скрие проблеми с несправедливост или робустност.
- **Прекомерно доверие в робустността:** Модел, който работи добре на тестови данни, може да бъде уязвим към малки промени или атаки.
- **Липса на разнообразие в тестовите случаи:** Тестовете трябва да включват различни сценарии, включително edge cases и adversarial inputs.
- **Пренебрегване на етични аспекти:** Техническите решения трябва да се съчетават с разбиране за социалните и етични последствия.

## 7. Short Retrieval Quiz
1. Какво представлява bias в контекста на AI?
2. Защо е важна робустността на един модел?
3. Какво е adversarial example?
4. Какви метрики могат да се използват за измерване на справедливост?
5. Какво е data distribution shift и как влияе на модела?
6. Назовете една техника за смекчаване на пристрастия.
7. Какво може да се случи, ако не тестваме робустността на системата?

## 8. Quick Recap
- Bias е систематично отклонение, което може да доведе до несправедливи резултати.
- Робустността гарантира стабилна работа на системата при различни и непредвидени условия.
- Тестването за пристрастия и робустност са взаимно свързани и критични за надеждността на AI.
- Методи като adversarial testing и анализ на fairness метрики са стандартни практики.
- Избягвайте типични грешки като пренебрегване на данните и ограничено тестване.
- Практическите задачи и реалните примери помагат за по-дълбоко разбиране.
- Етичните аспекти трябва да са интегрална част от процеса.

## 9. Spaced Review Plan

| Време след първоначално учене | Промпти за преговор                                  |
|-------------------------------|-----------------------------------------------------|
| 1 ден                         | Какво е bias и защо е важен? Какво означава робустност? |
| 3 дни                         | Назовете основните методи за тестване на bias и robustness. |
| 1 седмица                     | Обяснете как adversarial testing помага за робустността. |
| 1 месец                      | Прегледайте примери и типични грешки при bias и robustness testing. |