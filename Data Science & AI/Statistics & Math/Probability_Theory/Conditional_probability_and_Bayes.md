# Conditional_probability_and_Bayes

## 1. Activate Prior Knowledge

- Какво представлява вероятността и как я използваме за моделиране на несигурност в софтуерни системи?
- Как бихте оценили вероятността за дадено събитие, ако знаете, че е настъпило друго свързано събитие?
- В какви ситуации в изкуствения интелект бихте използвали информация за предишни събития, за да актуализирате вашите прогнози?

## 2. Overview

Условната вероятност е основен инструмент за моделиране на зависимостите между събития. Тя ни позволява да изчислим вероятността за едно събитие при условие, че друго вече е настъпило. Това е ключово за разбиране на причинно-следствени връзки и за вземане на решения при несигурност.

В контекста на изкуствения интелект и софтуерното инженерство, условната вероятност е в основата на много алгоритми за машинно обучение, диагностика и прогнозиране. Тя ни дава възможност да актуализираме нашите убеждения въз основа на нови данни, което е същността на Байесовия подход.

Байесовата теорема обединява условната вероятност с априорни знания, позволявайки ни да изчислим обратната вероятност – вероятността на хипотеза при наличието на наблюдавани данни. Това е фундаментален метод за адаптивно учене и вземане на решения в реално време.

## 3. Key Concepts

- **Условна вероятност (Conditional Probability)** – Вероятността за настъпване на събитие A при условие, че събитие B вече е настъпило. Моделира зависимост между събития, подобно на това как знаем, че дъждът увеличава вероятността за мокър тротоар.

- **Байесова теорема (Bayes' Theorem)** – Формула, която свързва условните вероятности и априорните вероятности, позволявайки да се изчисли вероятността на хипотеза при нови данни. Представете си я като начин да актуализирате вашите убеждения, когато получавате нова информация.

- **Априорна вероятност (Prior Probability)** – Началната вероятност за дадена хипотеза преди да се вземат предвид нови данни.

- **Апостериорна вероятност (Posterior Probability)** – Вероятността за хипотеза след като са взети предвид новите данни.

- **Независими събития (Independent Events)** – Събития, при които настъпването на едното не влияе на вероятността на другото. Аналогично на хвърляне на две различни монети.

## 4. Step-by-step Learning Path

1. **Разберете дефиницията на условната вероятност**
   - Фокус: Формулата P(A|B) = P(A ∩ B) / P(B)
   - Задача: Изчислете условната вероятност за пример с карти (например, вероятността да изтеглите дама, ако знаете, че картата е червена).
   - Въпроси: Какво означава P(A|B)? Как се различава от P(A)?

2. **Изучете Байесовата теорема и нейната формула**
   - Фокус: P(H|D) = [P(D|H) * P(H)] / P(D)
   - Задача: Приложете формулата за диагностика на болест с дадени вероятности.
   - Въпроси: Какво е априорното и апостериорното? Как се изчислява нормализиращият фактор P(D)?

3. **Практикувайте с реални данни и симулации**
   - Фокус: Използване на условна вероятност за актуализация на модели.
   - Задача: Напишете малък скрипт, който прилага Байесова теорема за класификация на текст (например, спам или не-спам).
   - Въпроси: Как новите данни променят апостериорната вероятност? Защо е важно да имаме точни априорни вероятности?

4. **Изследвайте независимостта и зависимостта между събития**
   - Фокус: Разпознаване кога условната вероятност се опростява.
   - Задача: Определете дали две събития са независими, използвайки пример с хвърляне на зарове.
   - Въпроси: Какво означава независимост? Как се изчислява P(A ∩ B) при независими събития?

5. **Приложете Байесовия подход в по-сложни системи**
   - Фокус: Байесови мрежи и вероятностни графови модели.
   - Задача: Анализирайте примерна Байесова мрежа с няколко променливи.
   - Въпроси: Как условната вероятност се използва за моделиране на сложни зависимости? Как се актуализират вероятностите в мрежата?

## 5. Examples

### Пример 1: Диагностика на болест

Представете си тест за болест, който е 99% точен (P(положителен тест|болен) = 0.99), но болестта е рядка (P(болен) = 0.001). Каква е вероятността човек с положителен тест наистина да е болен?

```python
# Дадени
P_disease = 0.001
P_no_disease = 1 - P_disease
P_pos_given_disease = 0.99
P_pos_given_no_disease = 0.05  # фалшиво положителен резултат

# Изчисляване на общата вероятност за положителен тест
P_pos = P_pos_given_disease * P_disease + P_pos_given_no_disease * P_no_disease

# Байесова теорема
P_disease_given_pos = (P_pos_given_disease * P_disease) / P_pos

print(f"Вероятност за болест при положителен тест: {P_disease_given_pos:.4f}")
```

### Пример 2: Класификация на имейли (спам/не-спам)

Използване на условна вероятност за оценка на вероятността, че имейл е спам, ако съдържа определена дума.

```python
# Примерни вероятности
P_spam = 0.4
P_not_spam = 0.6
P_word_given_spam = 0.7
P_word_given_not_spam = 0.1

# Изчисляване на P(spam|word)
P_word = P_word_given_spam * P_spam + P_word_given_not_spam * P_not_spam
P_spam_given_word = (P_word_given_spam * P_spam) / P_word

print(f"Вероятност имейлът да е спам, ако съдържа думата: {P_spam_given_word:.2f}")
```

### Пример 3: Независими събития

Вероятността да хвърлим две шестстенни зарчета и да получим 6 на първото и 3 на второто:

P(6 на първото) = 1/6  
P(3 на второто) = 1/6  
P(6 и 3) = P(6) * P(3) = 1/36

## 6. Common Pitfalls

- **Бъркане на условна и априорна вероятност** – Апостериорната вероятност винаги зависи от априорната, но не са еднакви.
- **Игнориране на нормализиращия фактор** – P(D) в Байесовата формула често се пропуска, което води до грешни резултати.
- **Неправилно предположение за независимост** – Много системи имат зависими събития, което изисква по-сложни модели.
- **Прекалена увереност при малко данни** – Байесовият подход е чувствителен към качеството и количеството на априорната информация.
- **Забравяне, че вероятностите трябва да са между 0 и 1** – Проверявайте винаги валидността на входните данни.

## 7. Short Retrieval Quiz

1. Каква е формулата за условна вероятност?
2. Какво представлява априорната вероятност?
3. Как Байесовата теорема свързва априорната и апостериорната вероятност?
4. Какво означава, че две събития са независими?
5. Защо е важно да включим нормализиращия фактор в Байесовата формула?
6. Как бихте използвали условната вероятност в класификация на данни?
7. Какво се случва с апостериорната вероятност, ако получим нови данни?

## 8. Quick Recap

- Условната вероятност описва вероятността за събитие при условие, че друго вече е настъпило.
- Байесовата теорема позволява актуализация на вероятности въз основа на нови данни.
- Априорната вероятност е началната ни оценка, а апостериорната – обновената след наблюдение.
- Независимите събития имат вероятности, които се умножават без условни зависимости.
- Байесовият подход е фундаментален за адаптивни системи и машинно обучение.
- Важно е да се избягват грешки при изчисленията и предположенията за зависимост.
- Практическото приложение изисква разбиране на теорията и умения за програмиране.

## 9. Spaced Review Plan

| Време след учене | Прегледен въпрос                          | Цел на прегледа                        |
|------------------|------------------------------------------|--------------------------------------|
| 1 ден            | Каква е формулата за условна вероятност? | Закрепване на основната дефиниция    |
| 3 дни            | Как се изчислява апостериорната вероятност? | Разбиране на Байесовата теорема       |
| 1 седмица        | Кога две събития са независими?          | Разграничаване на зависими и независими събития |
| 1 месец          | Как бихте приложили Байесовата теорема в реален проект? | Свързване на теорията с практиката   |