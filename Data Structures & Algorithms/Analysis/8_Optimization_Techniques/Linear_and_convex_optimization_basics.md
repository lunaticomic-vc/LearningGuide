# Linear_and_convex_optimization_basics

## 1. Activate Prior Knowledge

- Какво представлява оптимизацията и как я използваме в изграждането на AI системи?
- Можете ли да си представите пример, в който трябва да изберете най-доброто решение от множество възможности при ограничени ресурси?
- Какви типове функции и ограничения бихте очаквали да срещнете в задачи за оптимизация в софтуерното инженерство?

## 2. Overview

Оптимизацията е процесът на намиране на най-доброто решение според определени критерии, като минимизиране на разходи или максимизиране на ефективност. В контекста на AI и софтуерното инженерство, оптимизацията често се използва за обучение на модели, разпределение на ресурси и вземане на решения.

Линейната оптимизация е частен случай, при който целевата функция и ограниченията са линейни. Тя е добре изучена и има ефективни алгоритми за решаване, като симплексния метод. Конвексната оптимизация обобщава линейната, позволявайки нелинейни, но конвексни функции, които гарантират глобален оптимум.

Тези методи са фундаментални за разработване на надеждни и ефективни AI системи, тъй като позволяват формализиране и решаване на сложни задачи с множество променливи и ограничения. Разбирането им е ключово за всеки професионалист, който иска да създава оптимизирани и адаптивни решения.

## 3. Key Concepts

- **Optimization Problem** – Задача, която цели да намери стойности на променливи, максимизиращи или минимизиращи дадена функция при определени ограничения. Мислете за това като за търсене на най-добрия избор в множество възможности.
- **Objective Function (Целева функция)** – Функцията, която искаме да оптимизираме (максимизираме или минимизираме). Аналогия: целта на игра, която искаме да спечелим.
- **Constraints (Ограничения)** – Условия, които променливите трябва да удовлетворяват. Те ограничават възможните решения, подобно на правила в игра.
- **Feasible Region (Допустима област)** – Множеството от всички решения, които удовлетворяват ограниченията. Представете си го като легално поле за игра.
- **Linear Programming (Линейно програмиране)** – Оптимизация с линейна целева функция и линейни ограничения.
- **Convex Function (Конвексна функция)** – Функция, при която всеки сегмент между две точки на графиката лежи над или върху графиката. Това гарантира, че локален минимум е и глобален.
- **Convex Optimization (Конвексна оптимизация)** – Оптимизация на конвексни функции с конвексни ограничения, което осигурява по-лесно намиране на глобални оптимуми.
- **Simplex Method (Симплексен метод)** – Класически алгоритъм за решаване на линейни програми, който се движи по върховете на допустимата област.
- **Gradient Descent (Градиентен спуск)** – Итеративен метод за намиране на минимум на функция чрез движение в посока на най-стръмно намаляване.

## 4. Step-by-step Learning Path

1. **Запознаване с основите на оптимизацията**
   - Фокус: Разберете какво е оптимизация и защо е важна.
   - Задача: Намерете пример за оптимизационна задача в ежедневието или софтуер.
   - Въпроси: Какво е целева функция? Какво представляват ограниченията?

2. **Линейна оптимизация: формулиране и решаване**
   - Фокус: Научете как да формулирате линейна задача и да я решите с помощта на симплексния метод.
   - Задача: Решете малка линейна задача с 2 променливи и 3 ограничения.
   - Въпроси: Какво е допустима област? Как работи симплексният метод?

3. **Въведение в конвексната оптимизация**
   - Фокус: Разберете концепцията за конвексни функции и защо са важни.
   - Задача: Идентифицирайте дали дадена функция е конвексна.
   - Въпроси: Какво гарантира конвексността? Защо е важна за оптимизацията?

4. **Практическо решаване на конвексни задачи**
   - Фокус: Използвайте градиентен спуск за решаване на проста конвексна задача.
   - Задача: Имплементирайте градиентен спуск за минимизиране на квадратична функция.
   - Въпроси: Как се избира стъпката на градиентния спуск? Какво е локален и глобален минимум?

5. **Приложения в AI и софтуерно инженерство**
   - Фокус: Разгледайте как оптимизацията се използва в машинно обучение и разпределение на ресурси.
   - Задача: Анализирайте пример на оптимизационна задача в обучение на модел.
   - Въпроси: Как оптимизацията влияе на ефективността на AI моделите? Какви ограничения могат да възникнат?

## 5. Examples

### Пример 1: Линейна оптимизация за разпределение на ресурси

Имаме фабрика, която произвежда два продукта с печалби 40 и 30 лв. на бройка. Ограничени сме от 100 часа труд и 80 единици материал. Целта е да максимизираме печалбата.

```python
from scipy.optimize import linprog

c = [-40, -30]  # Максимизираме => минимизираме -печалба
A = [[1, 2], [3, 1]]  # Ограничения: труд и материал
b = [100, 80]

res = linprog(c, A_ub=A, b_ub=b, bounds=(0, None))
print("Оптимално производство:", res.x)
print("Максимална печалба:", -res.fun)
```

### Пример 2: Конвексна оптимизация с градиентен спуск

Минимизиране на функцията f(x) = (x-3)^2 + 4

```python
def f(x):
    return (x - 3)**2 + 4

def grad_f(x):
    return 2 * (x - 3)

x = 0  # Начална точка
alpha = 0.1  # Стъпка
for _ in range(50):
    x = x - alpha * grad_f(x)
print(f"Минимум при x = {x}, f(x) = {f(x)}")
```

### Пример 3: Оптимизация в машинно обучение

Минимизиране на средноквадратичната грешка (MSE) при линейна регресия чрез градиентен спуск.

```python
import numpy as np

X = np.array([[1], [2], [3], [4]])
y = np.array([2, 4, 6, 8])
w = 0.0
alpha = 0.01

for _ in range(1000):
    y_pred = w * X
    grad = -2 * np.mean(X * (y - y_pred))
    w = w - alpha * grad

print(f"Оптимален коефициент w: {w}")
```

## 6. Common Pitfalls

- **Неправилно формулиране на задачата** – Липса на ясно дефинирана целева функция или ограничения води до невалидни решения.
- **Игнориране на конвексността** – Опит да се решат неконвексни задачи с методи за конвексна оптимизация може да доведе до локални оптимуми.
- **Неподходящ избор на стъпка в градиентния спуск** – Твърде голяма стъпка може да пропусне минимума, твърде малка – да забави конвергенцията.
- **Пренебрегване на ограниченията** – Решения извън допустимата област са невалидни, затова ограниченията трябва да се спазват стриктно.
- **Липса на проверка за устойчивост** – В реални системи оптимизационните решения трябва да са устойчиви на шум и промени в данните.

## 7. Short Retrieval Quiz

1. Какво е целева функция в оптимизацията?
2. Какво означава, че една функция е конвексна?
3. Коя е основната разлика между линейна и конвексна оптимизация?
4. Какво представлява допустимата област?
5. Как работи симплексният метод?
6. Защо градиентният спуск може да не намери глобален минимум при неконвексни функции?
7. Какви са типичните ограничения в оптимизационни задачи?

## 8. Quick Recap

- Оптимизацията търси най-доброто решение според зададена цел и ограничения.
- Линейната оптимизация използва линейни функции и ограничения и се решава ефективно с методи като симплексния.
- Конвексната оптимизация обхваща по-широк клас задачи с гаранция за глобален оптимум.
- Конвексността на функцията е ключова за успешното намиране на оптимално решение.
- Градиентният спуск е често използван итеративен метод за решаване на конвексни задачи.
- В AI и софтуерното инженерство оптимизацията е основен инструмент за подобряване на модели и системи.
- Внимателното формулиране и спазване на ограниченията са критични за валидността на решенията.

## 9. Spaced Review Plan

| Време след учене | Промпт за преглед                                      |
|------------------|--------------------------------------------------------|
| 1 ден            | Обяснете с прости думи какво е линейна и конвексна оптимизация. |
| 3 дни            | Пример за задача с линейна оптимизация и как се решава. |
| 1 седмица        | Опишете ролята на конвексността и градиентния спуск.   |
| 1 месец          | Свържете оптимизацията с реален проблем в AI или софтуер. |