# Data_cleaning_normalization

## 1. Activate Prior Knowledge

- Каква е ролята на качеството на данните в изграждането на надеждни AI системи?
- Какви проблеми могат да възникнат, ако данните съдържат грешки, липсващи стойности или различни формати?
- Какво означава нормализация на данните и защо може да е необходима преди обучение на модел?

## 2. Overview

Почистването и нормализацията на данните са критични стъпки в процеса на подготовка на данните за анализ и машинно обучение. Целта на почистването е да се идентифицират и коригират грешки, липсващи стойности, дублирани записи и други аномалии, които могат да повлияят негативно на резултатите. Нормализацията, от своя страна, преобразува данните в стандартизиран формат или мащаб, което улеснява сравняването и обработката им.

В по-широк контекст, тези процеси са част от етапа на предварителна обработка на данните (data preprocessing), който е основополагащ за изграждането на стабилни и точни модели. Без качествено почистване и нормализация, дори най-модерните алгоритми могат да дадат неточни или непредсказуеми резултати. В софтуерното инженерство, тези практики гарантират, че системите работят с коректни и съвместими данни, което подобрява надеждността и поддръжката им.

## 3. Key Concepts

- **Data Cleaning** – процес на откриване и коригиране или премахване на грешни, непълни, дублирани или несъответстващи данни. Аналогия: почистване на грешки в текстов документ преди публикуване.
- **Normalization** – преобразуване на числови данни в стандартен мащаб, например чрез скалиране между 0 и 1 или стандартизиране с нулева средна стойност и единична дисперсия. Ментален модел: настройка на всички инструменти в оркестър на една и съща тоналност.
- **Missing Values** – липсващи данни в набора, които трябва да се обработят чрез заместване, изтриване или моделиране.
- **Outliers** – стойности, които се отклоняват значително от останалите данни и могат да изкривят анализа.
- **Data Imputation** – методи за запълване на липсващи стойности, например със средна стойност, медиана или предсказани стойности.
- **Feature Scaling** – част от нормализацията, която гарантира, че всички характеристики имат сходен мащаб, за да не доминират по-големите числови стойности.
- **Z-score Standardization** – метод за нормализация, при който всяка стойност се преобразува чрез изваждане на средната стойност и делене на стандартното отклонение.
- **Min-Max Scaling** – метод, който преобразува данните в интервала [0,1], като изважда минималната стойност и дели на разликата между максимална и минимална.

## 4. Step-by-step Learning Path

1. **Разбиране на значението на чистите данни**
   - Фокус: защо грешните и липсващи данни са проблем.
   - Задача: прегледайте примерен набор с грешки и липсващи стойности.
   - Въпроси: Какви видове грешки открихте? Как биха повлияли на анализа?

2. **Откриване и обработка на липсващи стойности**
   - Фокус: техники за идентифициране и запълване на липсващи данни.
   - Задача: приложете средна стойност за запълване на липсващи данни в таблица.
   - Въпроси: Кога е подходящо да изтриете редове с липсващи данни? Какви са рисковете?

3. **Идентифициране и управление на аномалии (outliers)**
   - Фокус: как да открием и решим проблема с аномалните стойности.
   - Задача: използвайте boxplot за визуализация на аномалии в набор от данни.
   - Въпроси: Как аномалиите влияят на средната стойност? Кога да ги запазим?

4. **Прилагане на нормализация**
   - Фокус: разлика между Min-Max и Z-score нормализация.
   - Задача: нормализирайте числови колони с двата метода и сравнете резултатите.
   - Въпроси: Кога е по-подходяща Z-score нормализация? Какво се случва при Min-Max с нови стойности извън диапазона?

5. **Интегриране на почистване и нормализация в реален проект**
   - Фокус: автоматизиране на процеса с код.
   - Задача: напишете скрипт, който почиства и нормализира набор от данни.
   - Въпроси: Как да валидирате, че процесът е успешен? Как да се справите с нови данни?

## 5. Examples

**Пример 1: Запълване на липсващи стойности с Pandas**

```python
import pandas as pd

data = {'Age': [25, 30, None, 22, None, 28]}
df = pd.DataFrame(data)

# Запълване на липсващи стойности със средна възраст
df['Age'].fillna(df['Age'].mean(), inplace=True)
print(df)
```

**Пример 2: Min-Max нормализация с Scikit-learn**

```python
from sklearn.preprocessing import MinMaxScaler
import numpy as np

data = np.array([[10], [20], [30], [40], [50]])
scaler = MinMaxScaler()
normalized_data = scaler.fit_transform(data)
print(normalized_data)
```

**Пример 3: Z-score стандартизация**

```python
from sklearn.preprocessing import StandardScaler

data = np.array([[10], [20], [30], [40], [50]])
scaler = StandardScaler()
standardized_data = scaler.fit_transform(data)
print(standardized_data)
```

## 6. Common Pitfalls

- **Игнориране на липсващи стойности** – води до грешки или изкривени резултати.
- **Премахване на твърде много данни** – може да намали представителността на набора.
- **Неправилен избор на метод за нормализация** – например Min-Max при данни с много аномалии.
- **Прилагане на нормализация преди разделяне на тренировъчни и тестови данни** – води до изтичане на информация (data leakage).
- **Недостатъчна проверка на резултатите след почистване** – липса на валидация може да остави грешки незабелязани.

## 7. Short Retrieval Quiz

1. Какво представлява data cleaning и защо е важна?
2. Кога е подходящо да използваме Min-Max нормализация?
3. Какво е data imputation?
4. Какви са рисковете при премахване на редове с липсващи данни?
5. Какво представлява Z-score стандартизация?
6. Защо е важно да не прилагаме нормализация преди разделяне на данните?
7. Как аномалиите могат да повлияят на анализа?

## 8. Quick Recap

- Почистването на данни елиминира грешки и липсващи стойности, подобрявайки качеството на анализа.
- Нормализацията стандартизира числовите данни, улеснявайки обучението на модели.
- Липсващите стойности могат да се обработват чрез изтриване или заместване (imputation).
- Изборът на метод за нормализация зависи от характера на данните и задачата.
- Важно е да се избягва data leakage при нормализация.
- Аномалиите трябва да се идентифицират и управляват внимателно.
- Автоматизацията на процеса е ключова за ефективна работа с големи набори от данни.

## 9. Spaced Review Plan

| Време след изучаване | Промпт за преговор                                   |
|----------------------|-----------------------------------------------------|
| 1 ден                | Обяснете с прости думи защо data cleaning е важна. |
| 3 дни                | Опишете разликите между Min-Max и Z-score нормализация. |
| 1 седмица            | Приложете data imputation на примерен набор с липсващи данни. |
| 1 месец              | Създайте кратък скрипт за автоматично почистване и нормализация. |