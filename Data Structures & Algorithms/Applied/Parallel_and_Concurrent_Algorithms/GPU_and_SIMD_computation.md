# GPU_and_SIMD_computation

## 1. Activate Prior Knowledge
- Какво знаете за паралелните изчисления и защо са важни в съвременните AI системи?
- Каква е ролята на графичните процесори (GPU) в ускоряването на изчислителни задачи?
- Какво представлява SIMD (Single Instruction, Multiple Data) и как може да се използва за оптимизация на софтуер?

## 2. Overview
GPU (Graphics Processing Unit) е специализиран хардуерен компонент, проектиран първоначално за обработка на графики, но днес широко използван за паралелни изчисления в различни области, включително изкуствен интелект и научни симулации. Той позволява едновременно изпълнение на хиляди нишки, което значително ускорява обработката на големи обеми данни.

SIMD е архитектурен модел, при който една инструкция се прилага едновременно върху множество данни. Това е ключова техника за постигане на висока производителност при обработка на вектори и матрици, типични за AI алгоритми и мултимедийни приложения.

GPU и SIMD често работят заедно: GPU използва SIMD паралелизъм, за да изпълнява множество операции едновременно. Разбирането на тази комбинация е критично за разработчиците, които искат да оптимизират своите AI модели и софтуерни системи за максимална ефективност.

## 3. Key Concepts
- **GPU (Graphics Processing Unit)** – Специализиран процесор, оптимизиран за паралелна обработка на големи обеми данни чрез множество ядра, подобно на армия от работници, които изпълняват задачи едновременно.
- **SIMD (Single Instruction, Multiple Data)** – Модел на изпълнение, при който една инструкция се прилага върху множество данни едновременно, като един учител, който дава една и съща задача на много ученици.
- **Thread (нишка)** – Най-малката единица изпълнение в GPU, която изпълнява инструкции паралелно с други нишки.
- **Warp / Wavefront** – Група от нишки, които изпълняват една и съща инструкция синхронно в GPU.
- **Memory Bandwidth** – Скоростта, с която данни могат да се прехвърлят между паметта и процесора; критична за производителността на GPU.
- **Kernel** – Функция, която се изпълнява на GPU върху множество нишки паралелно.
- **Latency vs Throughput** – Latency е времето за изпълнение на една операция, throughput е броят операции за единица време; GPU оптимизира throughput чрез паралелизъм.

## 4. Step-by-step Learning Path
1. **Основи на GPU архитектурата**
   - Фокус: Разберете как са организирани ядрата и нишките в GPU.
   - Задача: Прочетете документацията на CUDA или OpenCL за основните архитектурни елементи.
   - Въпроси: Какво е различното между CPU и GPU архитектура? Какво представлява warp?

2. **Запознаване със SIMD паралелизъм**
   - Фокус: Разберете принципа на SIMD и как се прилага в GPU.
   - Задача: Напишете прост SIMD код с помощта на векторни инструкции (например с Intrinsics).
   - Въпроси: Как SIMD подобрява производителността? Кога SIMD не е подходящ?

3. **Програмиране на GPU с CUDA или OpenCL**
   - Фокус: Научете как да пишете kernel-и и да управлявате нишки.
   - Задача: Напишете прост векторен сбор, който се изпълнява на GPU.
   - Въпроси: Как се разпределят нишките? Как се синхронизират?

4. **Оптимизация на паметта и управление на latency**
   - Фокус: Разберете различните видове памет в GPU и как да ги използвате ефективно.
   - Задача: Оптимизирайте kernel, като използвате shared memory.
   - Въпроси: Какво е shared memory? Какво е memory coalescing?

5. **Приложения в AI и машинно обучение**
   - Фокус: Разгледайте как GPU и SIMD ускоряват изчисленията в невронни мрежи.
   - Задача: Изпълнете тренировъчен процес на малък невронен модел с GPU ускорение.
   - Въпроси: Защо GPU е предпочитан за deep learning? Как SIMD се използва в матрични операции?

## 5. Examples
### Пример 1: Векторен сбор с CUDA
```cuda
__global__ void vectorAdd(float *A, float *B, float *C, int N) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < N) {
        C[i] = A[i] + B[i];
    }
}
```
Този kernel изпълнява паралелен сбор на два вектора, като всяка нишка обработва един елемент.

### Пример 2: SIMD с Intel Intrinsics (C++)
```cpp
#include <immintrin.h>

void add_simd(float* a, float* b, float* c, int n) {
    int i;
    for (i = 0; i < n; i += 8) {
        __m256 va = _mm256_loadu_ps(&a[i]);
        __m256 vb = _mm256_loadu_ps(&b[i]);
        __m256 vc = _mm256_add_ps(va, vb);
        _mm256_storeu_ps(&c[i], vc);
    }
}
```
Тук използваме AVX инструкции за едновременно добавяне на 8 float стойности.

### Пример 3: Оптимизация на паметта с shared memory в CUDA
```cuda
__global__ void sharedMemExample(float *input, float *output, int N) {
    __shared__ float tile[256];
    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    if (idx < N) {
        tile[threadIdx.x] = input[idx];
        __syncthreads();
        output[idx] = tile[threadIdx.x] * 2.0f;
    }
}
```
Използване на shared memory за намаляване на latency при достъп до данни.

## 6. Common Pitfalls
- **Неправилно управление на нишките** – Прекалено много или твърде малко нишки води до ниска производителност.
- **Игнориране на паметната йерархия** – Често се използва глобална памет вместо по-бърза shared memory, което забавя изпълнението.
- **Дивергенция на нишките (warp divergence)** – Когато нишките в един warp изпълняват различни инструкции, производителността пада.
- **Прекомерно използване на синхронизации** – Прекалено много __syncthreads() може да блокира изпълнението.
- **Недостатъчно оптимизиране на паметния достъп** – Липса на coalescing води до по-ниска пропускателна способност.
- **Пренебрегване на ограниченията на хардуера** – Например, ограничена shared memory или регистри.

## 7. Short Retrieval Quiz
1. Какво представлява SIMD и какво означава?
2. Каква е основната разлика между CPU и GPU архитектура?
3. Какво е warp в контекста на GPU?
4. Защо е важно да се използва shared memory в GPU програмирането?
5. Какво е warp divergence и как влияе на производителността?
6. Как GPU ускорява изчисленията в AI?
7. Какво означава memory coalescing?

## 8. Quick Recap
- GPU е хардуер, оптимизиран за масивен паралелизъм чрез хиляди нишки.
- SIMD позволява една инструкция да се изпълнява върху множество данни едновременно.
- GPU и SIMD са ключови за ускоряване на изчисления в AI и научни приложения.
- Ефективното програмиране изисква разбиране на нишки, паметна йерархия и синхронизация.
- Оптимизацията на паметния достъп и избягването на warp divergence са критични за производителността.
- CUDA и OpenCL са основните платформи за програмиране на GPU.
- Практическите задачи и примери помагат за усвояване на концепциите и техники.

## 9. Spaced Review Plan

| Време след учене | Прегледен въпрос / задача                                    |
|-------------------|-------------------------------------------------------------|
| 1 ден             | Обяснете какво е SIMD и защо е важен за GPU изчисленията.   |
| 3 дни             | Напишете прост CUDA kernel за векторен сбор.                |
| 1 седмица         | Оптимизирайте kernel с shared memory и обяснете ефекта.     |
| 1 месец           | Сравнете CPU и GPU архитектури и опишете кога да използвате всяка. |