# Hallucination_evaluation

## 1. Activate Prior Knowledge
- Какво разбирате под термина „халюцинация“ в контекста на изкуствения интелект и генеративните модели?
- Защо е важно да оценяваме халюцинациите в AI системите, особено в приложения като чатботове и автоматизирано съдържание?
- Как бихте свързали оценката на халюцинации с качеството и надеждността на софтуерни системи?

## 2. Overview
Халюцинациите в изкуствения интелект се отнасят до случаи, когато моделът генерира информация, която е невярна, неточна или изцяло измислена, но представена като факт. Оценката на халюцинациите е процесът на измерване и анализ на тези грешки, за да се подобри надеждността и доверието в AI системите.

Този процес е критичен в широк спектър от приложения, включително автоматизирано генериране на текст, медицински системи, юридически анализ и други, където грешна информация може да има сериозни последствия. В рамките на по-голяма система, оценката на халюцинациите служи като контролен механизъм, който помага да се открият и коригират потенциални проблеми преди внедряване.

Разбирането и измерването на халюцинациите е ключово за разработчиците и изследователите, които искат да създадат по-надеждни и етични AI решения. Без ефективна оценка, системите могат да генерират подвеждаща информация, което води до загуба на доверие и потенциални вреди.

## 3. Key Concepts
- **Hallucination** – Генериране на невярна или измислена информация от AI модел, която изглежда достоверна. Може да се сравни с „фалшив спомен“ в човешката памет.
- **Precision and Recall** – Метрики за оценка на точността и пълнотата на изхода на модела; важни за измерване на халюцинации, особено когато се сравнява с истински данни.
- **Ground Truth** – Истинските, проверени данни, с които се сравнява изходът на модела, за да се определи степента на халюцинация.
- **Human Evaluation** – Оценка, извършена от експерти или потребители, която често е необходима, тъй като автоматичните метрики не винаги улавят нюансите на халюцинациите.
- **Automated Metrics** – Методи като BLEU, ROUGE, FactCC и други, които автоматично измерват съвпадение с истински данни, но имат ограничения при откриване на халюцинации.
- **Confidence Calibration** – Процес на настройка на модела да изразява надеждност в своите отговори, което помага за идентифициране на потенциални халюцинации.

## 4. Step-by-step Learning Path
1. **Запознаване с понятието халюцинация в AI**
   - Фокус: Разберете какво представляват халюцинациите и защо са проблем.
   - Задача: Прочетете статия или глава от книга, описваща халюцинациите в езикови модели.
   - Въпроси: Какво е халюцинация? Защо е важно да ги откриваме?

2. **Изучаване на метрики за оценка**
   - Фокус: Научете основните автоматизирани метрики и техните ограничения.
   - Задача: Приложете BLEU и ROUGE метрики върху примерен текст и анализирайте резултатите.
   - Въпроси: Какво измерва BLEU? Защо автоматичните метрики не са достатъчни?

3. **Практическа оценка с човешки експерти**
   - Фокус: Разберете ролята на човешката оценка и как се провежда.
   - Задача: Организирайте малка анкета с колеги, за да оцените изход на AI модел за халюцинации.
   - Въпроси: Какви са предимствата и недостатъците на човешката оценка?

4. **Използване на инструменти за откриване на халюцинации**
   - Фокус: Запознайте се с автоматизирани инструменти и библиотеки.
   - Задача: Инсталирайте и използвайте FactCC или друг инструмент за проверка на факти върху изход от модел.
   - Въпроси: Как инструментите помагат за откриване на халюцинации? Какви са ограниченията им?

5. **Интегриране на оценката в разработката**
   - Фокус: Научете как да включите оценката на халюцинации в цикъла на разработка.
   - Задача: Създайте pipeline, който автоматично тества изхода на модел за халюцинации при всяка промяна.
   - Въпроси: Как оценката подобрява качеството на продукта? Как да автоматизираме процеса?

## 5. Examples
### Пример 1: Оценка на халюцинации в чатбот
```python
from transformers import pipeline

generator = pipeline('text-generation', model='gpt2')
output = generator("Кой е президент на България?", max_length=50)[0]['generated_text']

print("Generated:", output)
# Ръчна проверка дали отговорът съдържа халюцинации
```

### Пример 2: Използване на FactCC за автоматична проверка
```bash
# Инсталиране на FactCC
pip install factcc

# Примерна команда за проверка на фактологичната точност
factcc --input_file generated_texts.json --output_file factcc_results.json
```

### Пример 3: Човешка оценка на изход
- Създаване на анкета с въпроси: „Дали този отговор е вярен?“ и „Има ли несъответствия?“
- Събиране на оценки от 3 различни експерти и анализ на съгласуваността.

## 6. Common Pitfalls
- **Прекалено разчитане на автоматични метрики** – Те не улавят контекстуални и семантични грешки, което води до подценяване на халюцинациите.
- **Игнориране на човешката оценка** – Без човешки преглед, много халюцинации остават незабелязани.
- **Липса на дефиниция за „факт“** – Неяснотата какво е вярно затруднява оценката и води до субективизъм.
- **Недостатъчно разнообразие в тестовите данни** – Оценката върху тесен набор от данни не гарантира надеждност в реални условия.
- **Пренебрегване на контекста** – Халюцинациите често са контекстуални; оценката без контекст може да е подвеждаща.

## 7. Short Retrieval Quiz
1. Какво представлява халюцинацията в AI модел?
2. Защо автоматичните метрики не са достатъчни за оценка на халюцинации?
3. Каква е ролята на човешката оценка при оценката на халюцинации?
4. Какво е ground truth и защо е важно?
5. Какви са основните рискове при пренебрегване на халюцинациите в AI системи?
6. Как може да се интегрира оценката на халюцинации в разработката на софтуер?
7. Коя метрика бихте използвали за първоначална автоматична проверка на текст?

## 8. Quick Recap
- Халюцинациите са невярна или измислена информация, генерирана от AI.
- Оценката на халюцинации е ключова за надеждността и безопасността на AI системите.
- Автоматичните метрики помагат, но не са достатъчни сами по себе си.
- Човешката оценка допълва автоматичните методи и улавя контекстуални грешки.
- Инструменти като FactCC могат да автоматизират част от процеса.
- Важно е да се дефинира ясно какво е вярно и да се използват разнообразни данни.
- Оценката трябва да бъде интегрирана в цикъла на разработка за постоянни подобрения.

## 9. Spaced Review Plan

| Време след изучаване | Промпти за преговор                                   |
|----------------------|-------------------------------------------------------|
| 1 ден                | Какво е халюцинация? Избройте два метода за оценка.   |
| 3 дни                | Обяснете ролята на човешката оценка при халюцинации.  |
| 1 седмица            | Дайте пример за автоматична метрика и нейните ограничения. |
| 1 месец              | Как бихте интегрирали оценката на халюцинации в проект? |