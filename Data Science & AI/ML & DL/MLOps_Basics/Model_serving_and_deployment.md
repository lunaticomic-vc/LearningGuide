# Model_serving_and_deployment

## 1. Activate Prior Knowledge
- Какво представлява процесът на внедряване (deployment) в софтуерното инженерство и как той може да се прилага към модели за машинно обучение?
- Къде в жизнения цикъл на AI системата се появява етапът на model serving и каква е неговата роля?
- Какви предизвикателства очаквате при пренасянето на обучен модел от изследователската среда в продукционна среда?

## 2. Overview
Model serving and deployment са критични етапи в жизнения цикъл на AI системите, които осигуряват превръщането на обучен модел в достъпна, надеждна и мащабируема услуга. След като моделът е обучен и валидиран, той трябва да бъде интегриран в реална среда, където може да приема входни данни и да връща предсказания в реално време или на партиди.

Този процес включва множество технически и организационни аспекти – от избор на инфраструктура и форматиране на модела, през създаване на API-та, до мониторинг и обновяване на модела в продукция. Model serving е мостът между научните изследвания и бизнес приложенията, който позволява на AI системите да добавят реална стойност.

Значението на model serving and deployment се увеличава с нарастването на сложността на моделите и изискванията за ниска латентност, висока достъпност и сигурност. Без правилно внедряване, дори най-добрите модели остават неизползваеми.

## 3. Key Concepts
- **Model Serving** – процесът на предоставяне на обучен модел като услуга, която приема входни данни и връща предсказания. Можем да си го представим като „черна кутия“, която получава заявки и отговаря с резултати.
- **Deployment** – цялостното действие по пренасяне на модел от изследователската среда в продукционна, включително конфигуриране на инфраструктура, интеграция и управление.
- **API (Application Programming Interface)** – интерфейс, чрез който други системи комуникират с модела, обикновено REST или gRPC.
- **Containerization** – опаковане на модел и неговите зависимости в изолирана среда (например Docker), което улеснява разгръщането и мащабирането.
- **Latency** – времето, което отнема на модела да върне предсказание след получаване на заявка; критично за приложения в реално време.
- **Scalability** – способността на системата да обработва увеличаващ се брой заявки без спад в производителността.
- **Monitoring** – наблюдение на поведението и производителността на модела в продукция, включително откриване на деградация или drift.
- **Model Drift** – промяна във входните данни или в средата, която намалява точността на модела с времето.

## 4. Step-by-step Learning Path
1. **Разберете основите на model serving**
   - Фокус: Какво е model serving и как се различава от training.
   - Задача: Прочетете документация на TensorFlow Serving или TorchServe.
   - Въпроси: Какво е основното предназначение на model serving? Какви видове заявки обслужва?

2. **Научете се да създавате REST API за модел**
   - Фокус: Създаване на прост API с Flask или FastAPI, който зарежда модел и връща предсказания.
   - Задача: Напишете API, което приема JSON с входни данни и връща предсказание.
   - Въпроси: Как се обработват заявки в API? Как се сериализират входните и изходните данни?

3. **Опаковайте модела с Docker**
   - Фокус: Containerization за лесно разгръщане.
   - Задача: Създайте Dockerfile за вашия API и го стартирайте локално.
   - Въпроси: Какви са предимствата на контейнерите? Как Docker улеснява deployment?

4. **Разгледайте инструменти за автоматизирано разгръщане**
   - Фокус: Kubernetes, CI/CD pipelines.
   - Задача: Настройте прост Kubernetes deployment или използвайте GitHub Actions за автоматично разгръщане.
   - Въпроси: Какво е Kubernetes? Как CI/CD подобрява надеждността?

5. **Мониторинг и обновяване на модела**
   - Фокус: Метрики, логове, alert-и.
   - Задача: Интегрирайте Prometheus или друг мониторинг инструмент.
   - Въпроси: Как да разберем, че моделът деградира? Какво е model drift?

## 5. Examples
### Пример 1: Flask API за предсказания с sklearn модел
```python
from flask import Flask, request, jsonify
import joblib

app = Flask(__name__)
model = joblib.load('model.pkl')

@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json(force=True)
    features = data['features']
    prediction = model.predict([features])
    return jsonify({'prediction': prediction.tolist()})

if __name__ == '__main__':
    app.run(debug=True)
```

### Пример 2: Dockerfile за контейнеризация на Flask API
```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 5000
CMD ["python", "app.py"]
```

### Пример 3: Примерен Kubernetes deployment (deployment.yaml)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-serving
spec:
  replicas: 3
  selector:
    matchLabels:
      app: model-serving
  template:
    metadata:
      labels:
        app: model-serving
    spec:
      containers:
      - name: model-serving
        image: your-docker-image:latest
        ports:
        - containerPort: 5000
```

## 6. Common Pitfalls
- **Игнориране на латентността** – модели, които работят бързо в лаборатория, могат да имат неприемливо забавяне в продукция. Измервайте и оптимизирайте.
- **Липса на мониторинг** – без наблюдение не можете да откриете кога моделът започва да дава грешни резултати.
- **Твърде сложен deployment** – прекалено сложни инфраструктури могат да затруднят поддръжката и обновяването.
- **Недостатъчна обработка на грешки** – API трябва да връща ясни съобщения при невалидни входни данни или сривове.
- **Пренебрегване на сигурността** – отворени API-та без автентикация са рискови.
- **Необновяване на модела** – модели, които не се обновяват, губят точност с времето.

## 7. Short Retrieval Quiz
1. Какво представлява model serving?
2. Защо е важно да контейнеризираме моделите?
3. Какво е model drift и как може да се открие?
4. Кои са основните компоненти на един модел API?
5. Какво означава latency в контекста на model serving?
6. Какви инструменти могат да се използват за автоматизирано разгръщане?
7. Защо мониторингът е критичен след deployment?

## 8. Quick Recap
- Model serving превръща обучен модел в достъпна услуга за предсказания.
- Deployment включва инфраструктура, интеграция и управление на модела в продукция.
- API-та са интерфейсът за комуникация с модела.
- Контейнеризацията улеснява разгръщането и мащабирането.
- Мониторингът и обновяването са необходими за поддържане на качество и надеждност.
- Латентността и сигурността са ключови фактори за успешен deployment.
- Автоматизацията чрез CI/CD и Kubernetes подобрява ефективността и стабилността.

## 9. Spaced Review Plan

| Време след учене | Промпт за преглед                                      |
|------------------|-------------------------------------------------------|
| 1 ден            | Обяснете какво е model serving и защо е важен.        |
| 3 дни            | Избройте основните стъпки при deployment на модел.    |
| 1 седмица        | Опишете какво е model drift и как да го открием.      |
| 1 месец          | Прегледайте пример за API и Dockerfile за model serving.|