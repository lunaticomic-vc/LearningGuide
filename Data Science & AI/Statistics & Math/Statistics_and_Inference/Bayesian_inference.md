# Bayesian_inference

## 1. Activate Prior Knowledge

- Какво знаете за вероятностите и как те се използват за моделиране на несигурност в софтуерни системи?
- Как бихте обяснили разликата между честа и баесова интерпретация на вероятността?
- Можете ли да предвидите как бихте актуализирали своите убеждения при получаване на нова информация в контекста на машинно обучение?

## 2. Overview

Байесовото изводване е метод за актуализиране на вероятностите за хипотези въз основа на нови данни. То е фундаментален инструмент в статистиката и машинното обучение, който позволява да се моделира несигурност и да се вземат решения при непълна информация. В контекста на изкуствения интелект, байесовото изводване често се използва за обучение на модели, оценка на параметри и предсказване.

В по-широката система, байесовото изводване служи като мост между предварителните знания (prior) и наблюдаваните данни (likelihood), за да се получи актуализирано знание (posterior). Това е особено важно в динамични среди, където данните пристигат последователно и системата трябва да се адаптира.

Значението на байесовото изводване се крие в неговата гъвкавост и теоретична обоснованост. Той позволява интегриране на експертни знания и автоматично подобряване на модели, което го прави незаменим в съвременните AI системи и софтуерни инженерни практики.

## 3. Key Concepts

- **Prior (Предварително разпределение)** – Вероятностното разпределение, което отразява нашите убеждения за параметрите преди да видим нови данни. Можем да го сравним с предварителна хипотеза, която искаме да проверим.
- **Likelihood (Функция на вероятността)** – Вероятността да наблюдаваме дадените данни при фиксирани параметри. Аналогично на това да оценяваме колко добре хипотезата обяснява наблюденията.
- **Posterior (Постериорно разпределение)** – Актуализираното разпределение на параметрите след като сме видели данните. Това е нашето ново убеждение, комбиниращо prior и likelihood.
- **Bayes’ Theorem (Байесова теорема)** – Математическата формула, която свързва prior, likelihood и posterior:  
  \[
  P(\theta|D) = \frac{P(D|\theta)P(\theta)}{P(D)}
  \]  
  където \(\theta\) са параметрите, а \(D\) – данните.
- **Conjugate Prior (Съпътстващ prior)** – Специален тип prior, който позволява аналитично изчисляване на posterior, улеснявайки изводването.
- **Marginal Likelihood (Маргинална вероятност)** – Вероятността за наблюдаваните данни, интегрирана по всички възможни параметри. Използва се за сравнение на модели.
- **Inference (Изводване)** – Процесът на изчисляване или апроксимация на posterior разпределението.

## 4. Step-by-step Learning Path

1. **Запознайте се с основите на вероятностите и условната вероятност**  
   - Задача: Пресметнете условни вероятности за прости събития (например, хвърляне на зар).  
   - Въпроси: Какво е условна вероятност? Как се изчислява?

2. **Разберете Байесовата теорема и нейното приложение**  
   - Задача: Използвайте формулата на Байес за изчисляване на posterior с даден prior и likelihood.  
   - Въпроси: Как prior и likelihood влияят на posterior? Какво означава нормализиращият фактор?

3. **Изучете различни видове prior и тяхното влияние**  
   - Задача: Сравнете резултатите с различни prior-и върху един и същ набор от данни.  
   - Въпроси: Какво е conjugate prior? Защо е полезен?

4. **Практикувайте изводване с реални данни и модели**  
   - Задача: Имплементирайте прост байесов класификатор (например Naive Bayes) върху набор от текстови данни.  
   - Въпроси: Как се изчисляват вероятностите за класовете? Как се използва posterior за класификация?

5. **Изследвайте техники за апроксимация на posterior (MCMC, Variational Inference)**  
   - Задача: Използвайте библиотека (например PyMC3 или Stan) за изводване на параметри на сложен модел.  
   - Въпроси: Защо понякога е невъзможно да се изчисли posterior аналитично? Какви са предимствата на MCMC?

## 5. Examples

### Пример 1: Диагностика на болест

Да предположим, че имаме тест за болест с 99% точност и знаем, че 1% от населението е заразено. Каква е вероятността човек да е болен, ако тестът е положителен?

```python
prior = 0.01  # P(болен)
likelihood = 0.99  # P(тест+ | болен)
false_positive = 0.01  # P(тест+ | здрав)

posterior = (likelihood * prior) / (likelihood * prior + false_positive * (1 - prior))
print(f"Вероятност за болест при положителен тест: {posterior:.2f}")
```

### Пример 2: Naive Bayes за класификация на текст

```python
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer

texts = ["spam message", "important email", "buy now", "meeting schedule"]
labels = [1, 0, 1, 0]  # 1 = spam, 0 = not spam

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(texts)

model = MultinomialNB()
model.fit(X, labels)

test_text = vectorizer.transform(["free buy now"])
prediction = model.predict(test_text)
print("Spam" if prediction[0] == 1 else "Not spam")
```

### Пример 3: Изводване с MCMC (PyMC3)

```python
import pymc3 as pm
import numpy as np

data = np.random.binomial(1, 0.7, size=100)

with pm.Model() as model:
    p = pm.Beta('p', alpha=1, beta=1)
    obs = pm.Bernoulli('obs', p=p, observed=data)
    trace = pm.sample(1000, tune=1000)

pm.plot_posterior(trace)
```

## 6. Common Pitfalls

- **Игнориране на prior** – Приемането на prior като незначителен може да доведе до неправилни изводи, особено при малко данни.
- **Неправилно моделиране на likelihood** – Ако likelihood не отразява реалния процес, posterior ще бъде изкривен.
- **Прекалено сложни модели без достатъчно данни** – Това води до overfitting и неустойчиви оценки.
- **Забравяне на нормализиращия фактор** – Понякога се пренебрегва, което води до неправилни вероятности.
- **Лош избор на prior** – Субективните или неподходящи prior-и могат да доминират резултатите.
- **Неадекватна апроксимация на posterior** – При използване на MCMC или вариационни методи, лоша конвергенция или приближения могат да изкривят изводите.

## 7. Short Retrieval Quiz

1. Какво представлява prior в байесовото изводване?
2. Как се изчислява posterior според Байесовата теорема?
3. Каква е ролята на likelihood?
4. Какво е conjugate prior и защо е полезен?
5. Защо понякога е необходимо да използваме MCMC?
6. Какво може да се случи, ако изберем неподходящ prior?
7. Как байесовото изводване помага при вземане на решения в AI?

## 8. Quick Recap

- Байесовото изводване комбинира предварителни знания и нови данни, за да актуализира убеждения.
- Prior, likelihood и posterior са ключови компоненти, свързани чрез Байесовата теорема.
- Изборът на prior и правилното моделиране на likelihood са критични за качеството на изводите.
- Практическото приложение включва класификация, параметрична оценка и адаптивно обучение.
- При сложни модели се използват техники за апроксимация като MCMC.
- Общите грешки включват пренебрегване на prior и лошо моделиране.
- Байесовото изводване е мощен инструмент за работа с несигурност в AI и софтуерното инженерство.

## 9. Spaced Review Plan

| Време       | Промпт за преглед                                      |
|-------------|--------------------------------------------------------|
| 1 ден       | Обяснете с прости думи какво е prior и posterior.      |
| 3 дни       | Пресметнете posterior с даден prior и likelihood.      |
| 1 седмица   | Опишете приложението на байесовото изводване в AI.     |
| 1 месец     | Разгледайте пример с MCMC и обяснете защо е нужен.     |