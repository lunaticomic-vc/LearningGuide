# TensorFlow_PyTorch_JAX

## 1. Activate Prior Knowledge
- Какво представлява машинното обучение и как се използват числени изчисления за обучение на модели?
- Какви са основните компоненти на софтуерна библиотека за дълбоко обучение?
- Как бихте сравнили ролята на TensorFlow, PyTorch и JAX в изграждането на AI системи?

## 2. Overview
TensorFlow, PyTorch и JAX са водещи библиотеки за числени изчисления и дълбоко обучение, които предоставят мощни инструменти за изграждане, обучение и внедряване на невронни мрежи. Те служат като основа за разработка на AI модели, като осигуряват автоматично диференциране, оптимизация и работа с GPU/TPU ускорение.

TensorFlow е създаден от Google и е известен със своята гъвкавост и мащабируемост, особено в продукционни среди. PyTorch, разработен от Facebook, се отличава с динамичен граф и лесна за използване API, което го прави предпочитан избор за изследователи и прототипиране. JAX, също от Google, комбинира NumPy-подобен синтаксис с автоматично диференциране и компилация, което го прави изключително подходящ за научни изчисления и експериментални модели.

Разбирането на разликите и силните страни на тези библиотеки е ключово за ефективно разработване на AI системи, оптимизиране на производителността и адаптиране към различни изчислителни среди.

## 3. Key Concepts
- **Тензор** – Многоизмерен масив от числа, основната структура за данни в TensorFlow, PyTorch и JAX. Можете да го мислите като разширена версия на матрица.
- **Автоматично диференциране (Autograd)** – Механизъм за автоматично изчисляване на производни, необходим за обучение на невронни мрежи чрез обратно разпространение.
- **Граф на изчисления (Computation Graph)** – Абстракция, която описва последователността от операции върху тензори. TensorFlow използва статичен граф, докато PyTorch и JAX използват динамичен.
- **GPU/TPU ускорение** – Използване на специализирани хардуерни ускорители за значително по-бързо изпълнение на изчисленията.
- **JIT компилация (Just-In-Time)** – Техника за компилиране на код по време на изпълнение, използвана от JAX за оптимизация на производителността.
- **API (Application Programming Interface)** – Набор от функции и методи, които библиотеката предоставя за изграждане и обучение на модели.

## 4. Step-by-step Learning Path
1. **Запознаване с основите на тензорите**
   - Фокус: Създаване и манипулиране на тензори в TensorFlow, PyTorch и JAX.
   - Задача: Напишете код за създаване на 3x3 матрица и изчислете нейния трансфер.
   - Въпроси: Какво е тензор? Как се различава от обикновена матрица?

2. **Автоматично диференциране**
   - Фокус: Разберете как се изчисляват градиенти в трите библиотеки.
   - Задача: Имплементирайте проста функция и изчислете нейната производна.
   - Въпроси: Как работи автоматичното диференциране? Какви са разликите между TensorFlow и PyTorch в това отношение?

3. **Изграждане на прост невронен модел**
   - Фокус: Създаване на еднослоен перцептрон за класификация.
   - Задача: Обучете модел върху малък набор от данни (например MNIST).
   - Въпроси: Как се дефинира модел в TensorFlow и PyTorch? Как се извършва обучението?

4. **Оптимизация и ускорение**
   - Фокус: Използване на GPU/TPU и JIT компилация.
   - Задача: Изпълнете обучението на GPU и оптимизирайте кода с JAX JIT.
   - Въпроси: Как се активира GPU в TensorFlow и PyTorch? Какво е JIT и как помага на JAX?

5. **Производствено внедряване**
   - Фокус: Запознаване с инструменти за експортиране и внедряване.
   - Задача: Експортирайте обучен модел и го заредете в отделно приложение.
   - Въпроси: Какви са формати за съхранение на модели? Какви са предизвикателствата при внедряване?

## 5. Examples

### TensorFlow: Създаване на тензор и изчисляване на градиент
```python
import tensorflow as tf

x = tf.Variable(3.0)
with tf.GradientTape() as tape:
    y = x ** 2
dy_dx = tape.gradient(y, x)
print(dy_dx.numpy())  # Изход: 6.0
```

### PyTorch: Проста невронна мрежа
```python
import torch
import torch.nn as nn
import torch.optim as optim

model = nn.Linear(10, 1)
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

inputs = torch.randn(5, 10)
targets = torch.randn(5, 1)

outputs = model(inputs)
loss = criterion(outputs, targets)
loss.backward()
optimizer.step()
```

### JAX: JIT компилирана функция
```python
import jax
import jax.numpy as jnp

@jax.jit
def f(x):
    return jnp.sin(x) ** 2 + jnp.cos(x)

print(f(3.0))
```

## 6. Common Pitfalls
- **Неправилно управление на графа в TensorFlow 1.x** – Статичният граф изисква внимателно дефиниране; използвайте TensorFlow 2.x с eager execution.
- **Забравяне на `.backward()` в PyTorch** – Без извикване на backward() градиентите няма да се изчислят.
- **Неправилно използване на JIT в JAX** – Функциите трябва да са чисти (без странични ефекти), за да се компилират правилно.
- **Несъвместимост на тензорни размери** – Винаги проверявайте размерите преди операции като матрично умножение.
- **Игнориране на хардуерното ускорение** – Активирайте GPU/TPU, за да избегнете бавни изчисления.

## 7. Short Retrieval Quiz
1. Какво е тензор и защо е важен в дълбокото обучение?
2. Каква е основната разлика между статичен и динамичен граф?
3. Как се изчисляват градиенти в PyTorch?
4. Какво представлява JIT компилацията в JAX?
5. Коя библиотека е предпочитана за бързо прототипиране и защо?
6. Какво трябва да направите, за да използвате GPU в TensorFlow?
7. Какво е автоматично диференциране?

## 8. Quick Recap
- TensorFlow, PyTorch и JAX са ключови библиотеки за дълбоко обучение и числени изчисления.
- Тензорите са основната структура за данни, върху която се извършват операции.
- Автоматичното диференциране позволява ефективно обучение на модели чрез изчисляване на градиенти.
- TensorFlow използва статичен граф, докато PyTorch и JAX използват динамичен.
- JAX комбинира NumPy синтаксис с JIT компилация за висока производителност.
- Използването на GPU/TPU ускорение е критично за мащабни изчисления.
- Практическото овладяване изисква работа с модели, оптимизация и внедряване.

## 9. Spaced Review Plan

| Време след учене | Прегледен въпрос                                   |
|------------------|---------------------------------------------------|
| 1 ден            | Какво е тензор и как се използва в TensorFlow?   |
| 3 дни            | Обяснете разликата между статичен и динамичен граф. |
| 1 седмица        | Как работи автоматичното диференциране в PyTorch? |
| 1 месец          | Кога и защо да използваме JIT компилация в JAX?  |