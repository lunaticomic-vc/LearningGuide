# Cross_validation

## 1. Activate Prior Knowledge
- Какво представлява разделянето на данни на тренировъчни и тестови множества и защо е важно при изграждането на AI модели?
- Как бихте оценили надеждността на един модел, ако разполагате само с ограничен набор от данни?
- Какви са възможните проблеми при използването на само едно разделяне на данните за обучение и тестване?

## 2. Overview
Cross-validation е статистически метод за оценка на представянето на машиннообучителни модели, който позволява по-обективна и стабилна оценка чрез многократно разделяне на наличните данни. Той помага да се избегне пренасищане (overfitting) и да се гарантира, че моделът ще работи добре върху нови, невиждани данни.

В по-широк контекст, cross-validation е ключова стъпка в процеса на разработка на AI системи, особено при ограничени данни, където традиционното разделяне на тренировъчни и тестови множества може да доведе до пристрастия в оценката. Този метод осигурява надеждна основа за избор на най-добрия модел и неговите хиперпараметри.

Cross-validation не само подобрява точността на оценката, но и подпомага откриването на модели, които са стабилни и обобщаващи, което е критично в реални приложения като медицинска диагностика, финансови прогнози и автономни системи.

## 3. Key Concepts
- **Fold (Сгъвка)** – Една от равните части, на които се разделят данните при cross-validation. Моделът се обучава на всички folds, освен един, който се използва за тестване.
- **k-Fold Cross-validation** – Метод, при който данните се разделят на k folds; всеки fold се използва веднъж като тестово множество, а останалите k-1 folds – за обучение.
- **Overfitting (Пренасищане)** – Ситуация, при която моделът се научава твърде добре на тренировъчните данни, включително шум и аномалии, и не се справя добре с нови данни.
- **Underfitting (Недонасищане)** – Когато моделът е твърде прост и не успява да улови важните зависимости в данните.
- **Validation Set (Валидационно множество)** – Част от данните, използвана за настройка на хиперпараметри, различна от тренировъчните и тестовите множества.
- **Stratified Cross-validation** – Вариант на cross-validation, при който разпределението на класовете в отделните folds се запазва, за да се избегне пристрастие при неравномерни класове.

## 4. Step-by-step Learning Path
1. **Разбиране на основната идея на cross-validation**  
   - Фокус: Концепцията за разделяне на данните на folds и многократна оценка.  
   - Задача: Разделете малък набор от данни на 5 folds и ръчно проследете как се обучава и тества моделът.  
   - Въпроси: Какво е fold? Защо е важно да се използват различни folds за тестване?

2. **Имплементиране на k-Fold cross-validation**  
   - Фокус: Използване на библиотека (например scikit-learn) за автоматично изпълнение на k-Fold.  
   - Задача: Напишете код, който прилага 5-Fold cross-validation върху прост класификатор (напр. Logistic Regression).  
   - Въпроси: Как се изчислява средната точност? Какво означава вариацията между folds?

3. **Изучаване на stratified cross-validation**  
   - Фокус: Разбиране на важността на балансираното разпределение на класовете.  
   - Задача: Сравнете резултатите от обикновен и stratified cross-validation върху неравномерно разпределени класове.  
   - Въпроси: Как stratified cross-validation подобрява оценката? Кога е особено полезно?

4. **Използване на cross-validation за избор на хиперпараметри**  
   - Фокус: Настройка на параметри чрез Grid Search с cross-validation.  
   - Задача: Използвайте GridSearchCV за избор на оптимални параметри на SVM модел.  
   - Въпроси: Как cross-validation помага при избора на хиперпараметри? Какво е trade-off между броя folds и времето за обучение?

5. **Интерпретиране и докладване на резултатите**  
   - Фокус: Анализ на средна точност, стандартно отклонение и надеждност на оценката.  
   - Задача: Напишете кратък доклад с интерпретация на резултатите от cross-validation.  
   - Въпроси: Какво означава висока вариация между folds? Как да преценим дали моделът е стабилен?

## 5. Examples

### Пример 1: 5-Fold Cross-validation с Logistic Regression (Python)
```python
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

data = load_iris()
X, y = data.data, data.target
model = LogisticRegression(max_iter=200)

scores = cross_val_score(model, X, y, cv=5)
print(f"Средна точност: {scores.mean():.3f}, Стандартно отклонение: {scores.std():.3f}")
```

### Пример 2: Stratified k-Fold за неравномерни класове
```python
from sklearn.datasets import make_classification
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import numpy as np

X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.9, 0.1], random_state=42)
skf = StratifiedKFold(n_splits=5)
model = RandomForestClassifier()

accuracies = []
for train_index, test_index in skf.split(X, y):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    accuracies.append(accuracy_score(y_test, preds))

print(f"Средна точност: {np.mean(accuracies):.3f}")
```

### Пример 3: Grid Search с Cross-validation
```python
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
grid = GridSearchCV(SVC(), param_grid, cv=5)
grid.fit(X, y)

print(f"Най-добри параметри: {grid.best_params_}")
print(f"Най-добър резултат: {grid.best_score_:.3f}")
```

## 6. Common Pitfalls
- **Използване на тестовото множество за избор на модел или хиперпараметри** – води до оптимистична оценка и пренасищане. Винаги използвайте отделно тестово множество, което не участва в cross-validation.
- **Неправилно разбъркване на данните** – ако данните не са разбъркани, folds могат да бъдат пристрастни, особено при времеви серии или групирани данни.
- **Пренебрегване на stratification при неравномерни класове** – може да доведе до folds, които не представят реалното разпределение, и съответно до неточни оценки.
- **Избор на твърде малък или твърде голям брой folds** – малък брой folds води до по-голямо пристрастие, а твърде голям (напр. Leave-One-Out) – до висока вариация и дълго време за обучение.
- **Неотчитане на зависимост между folds при групирани данни** – например, при медицински изследвания, където данните от един пациент не трябва да са в различни folds.

## 7. Short Retrieval Quiz
1. Какво представлява fold в контекста на cross-validation?
2. Защо stratified cross-validation е важен при неравномерни класове?
3. Какво е основното предимство на cross-validation пред простото разделяне на данните на тренировъчни и тестови?
4. Как cross-validation помага при избора на хиперпараметри?
5. Какви са рисковете при използване на тестовото множество за настройка на модела?
6. Какво означава overfitting и как cross-validation помага да се избегне?
7. Какъв е trade-off между броя folds и времето за обучение?

## 8. Quick Recap
- Cross-validation е метод за надеждна оценка на машиннообучителни модели чрез многократно разделяне на данните.
- k-Fold cross-validation разделя данните на k равни части, като всяка служи веднъж за тест и k-1 пъти за обучение.
- Stratified cross-validation запазва разпределението на класовете във всяка сгъвка, което е критично при неравномерни класове.
- Cross-validation помага да се избегне overfitting и да се изберат оптимални хиперпараметри.
- Важно е да не се използва тестовото множество за избор на модел или параметри.
- Правилното разбъркване и разделяне на данните са ключови за валидна оценка.
- Балансът между броя folds и ресурсите за обучение влияе на точността и времето за изпълнение.

## 9. Spaced Review Plan

| Време след учене | Промпт за преговор                                   |
|------------------|-----------------------------------------------------|
| 1 ден            | Обяснете какво е k-Fold cross-validation и защо се използва. |
| 3 дни            | Как stratified cross-validation подобрява оценката при неравномерни класове? |
| 1 седмица        | Опишете процеса на избор на хиперпараметри с помощта на cross-validation. |
| 1 месец          | Избройте и обяснете основните грешки при прилагане на cross-validation. |