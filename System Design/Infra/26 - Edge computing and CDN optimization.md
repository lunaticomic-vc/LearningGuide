# 26 - Edge computing and CDN optimization

## 1. Activate Prior Knowledge

- Какво представлява традиционната облачна инфраструктура и какви са нейните ограничения по отношение на латентност и мащабируемост?
- Какви предизвикателства възникват при доставката на големи обеми данни (напр. видео, AI inference) до потребители по целия свят?
- Можете ли да си представите сценарий, в който обработката на данни по-близо до крайния потребител би подобрила производителността на дадено приложение?

## 2. Overview

Edge computing и Content Delivery Network (CDN) optimization са ключови технологии за съвременните разпределени системи, особено когато се изисква ниска латентност, висока производителност и надеждност. Edge computing позволява обработката на данни да се случва по-близо до източника или потребителя, вместо да се изпраща всичко към централен облак. Това намалява времето за реакция и натоварването на мрежата.

CDN оптимизацията се фокусира върху ефективното разпространение на съдържание (като уеб страници, видео, AI модели) чрез географски разпределени сървъри, които кешират и доставят данни възможно най-близо до потребителя. В комбинация, edge computing и CDN позволяват мащабируеми, устойчиви и бързи услуги, които са критични за AI приложения, IoT, стрийминг платформи и други.

В контекста на AI системи, edge и CDN оптимизацията позволяват inference (изпълнение на модели) да се случва локално, което е особено важно за приложения, изискващи реално време (напр. автономни автомобили, умни фабрики). Тези технологии също така подобряват сигурността и поверителността, като намаляват нуждата от изпращане на чувствителни данни към централни сървъри.

## 3. Key Concepts

- Edge computing – Децентрализирана обработка на данни, която се случва близо до мястото на възникване на данните (edge), а не в централен облак. Мислете за това като за "мини-облаци" разположени навсякъде.
- CDN (Content Delivery Network) – Мрежа от географски разпределени сървъри, които кешират и доставят съдържание бързо до потребителите. Представете си го като много "копия" на вашия сайт, разпръснати по света.
- Latency (Латентност) – Забавянето между изпращането на заявка и получаването на отговор. Колкото по-близо е сървърът, толкова по-ниска е латентността.
- Caching – Съхранение на често използвани данни на по-близки сървъри, за да се ускори достъпът до тях.
- Load balancing – Разпределяне на трафика между множество сървъри, за да се избегне претоварване и да се осигури висока наличност.
- AI inference at the edge – Изпълнение на обучени AI модели директно на edge устройства или edge сървъри, което намалява нуждата от централизирана обработка.
- Origin server – Главният сървър, от който произлиза съдържанието, което CDN или edge nodes разпространяват.

## 4. Step-by-step Learning Path

1. **Разберете архитектурата на edge computing и CDN**
   - Фокус: Как са структурирани edge и CDN системите.
   - Практическа задача: Нарисувайте схема на типична CDN архитектура с edge nodes.
   - Retrieval: Каква е разликата между edge node и origin server? Какво е основното предимство на edge computing?

2. **Изследвайте принципите на кеширане и репликация**
   - Фокус: Как работи кеширането в CDN и защо е важно.
   - Практическа задача: Конфигурирайте CDN за статичен уеб сайт (напр. чрез Cloudflare или AWS CloudFront).
   - Retrieval: Как кеширането намалява латентността? Какво се случва при cache miss?

3. **Научете за оптимизация на маршрутизацията и load balancing**
   - Фокус: Как се избира най-близкият или най-малко натоварен edge сървър.
   - Практическа задача: Използвайте инструмент (напр. traceroute или CDN provider dashboard), за да проследите пътя на заявка до edge node.
   - Retrieval: Как load balancing подобрява надеждността? Как се определя най-близкият edge node?

4. **Внедрете AI inference на edge**
   - Фокус: Как да разположите AI модел за inference на edge устройство или edge сървър.
   - Практическа задача: Деплойнете малък TensorFlow Lite модел на Raspberry Pi или използвайте AWS Greengrass.
   - Retrieval: Какви са предимствата на AI inference на edge? Кога е по-добре inference да се случва в облака?

5. **Мониторинг и оптимизация на производителността**
   - Фокус: Как се измерва и подобрява latency, throughput и cache hit rate.
   - Практическа задача: Настройте мониторинг на latency и cache hit rate чрез CDN dashboard.
   - Retrieval: Как се интерпретират показателите latency и cache hit rate? Какви действия предприемате при нисък cache hit rate?

## 5. Examples

### Пример 1: Доставяне на видео съдържание чрез CDN

Когато потребител в София иска да гледа видео от световна платформа (напр. YouTube), заявката му се обслужва от най-близкия CDN сървър, който вече е кеширал видеото. Ако видеото не е налично, CDN сървърът го изтегля от origin server и го кешира за следващи заявки.

### Пример 2: AI inference на edge устройство

```python
import tensorflow as tf
import numpy as np

# Зареждане на TensorFlow Lite модел за edge inference
interpreter = tf.lite.Interpreter(model_path="model.tflite")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

input_data = np.array([[0.5, 0.2, 0.1]], dtype=np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)
interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
print("Inference result:", output_data)
```
Този код изпълнява inference на edge устройство (напр. Raspberry Pi), без нужда от връзка с централен облак.

### Пример 3: Оптимизация на кеширане в CDN

В CDN конфигурация може да се зададе "cache-control" header, който определя колко дълго дадено съдържание да се пази в кеша:

```
Cache-Control: public, max-age=86400
```
Това указва на CDN да пази съдържанието 24 часа, което намалява натоварването към origin server.

## 6. Common Pitfalls

- **Прекалено кратък cache lifetime** – Ако съдържанието се кешира за твърде кратко време, се увеличават заявките към origin server и се губят предимствата на CDN.
- **Липса на мониторинг** – Без проследяване на latency и cache hit rate, проблемите остават незабелязани и не се оптимизира производителността.
- **Недостатъчно географско покритие** – Ако edge/CDN сървърите не са достатъчно близо до потребителите, латентността остава висока.
- **Неоптимизирана AI inference архитектура** – Изпълнение на тежки AI модели на неподходящи edge устройства води до забавяне или грешки.

## 7. Short Retrieval Quiz

1. Каква е основната разлика между edge computing и традиционния облак?
2. Как CDN намалява латентността при доставката на съдържание?
3. Какво означава cache hit rate и защо е важен?
4. Какви са предимствата на AI inference на edge спрямо inference в облака?
5. Как load balancing подобрява надеждността на системата?
6. Какво се случва при cache miss в CDN?
7. Защо е важно да се следи latency при edge/CDN решения?

## 8. Quick Recap

- Edge computing позволява обработка на данни близо до потребителя, намалявайки латентността.
- CDN оптимизира доставката на съдържание чрез кеширане на данни на разпределени сървъри.
- Кеширането и load balancing са ключови техники за бързина и надеждност.
- AI inference на edge подобрява реакцията в реално време и намалява нуждата от централен облак.
- Мониторингът на latency и cache hit rate е критичен за оптимизация.
- Правилната конфигурация на cache-control header подобрява ефективността на CDN.
- Недостатъчното географско покритие или лоша архитектура могат да компрометират предимствата на edge/CDN.

## 9. Spaced Review Plan

| Review Interval | Prompt                                                                 |
|-----------------|------------------------------------------------------------------------|
| 1 day           | Обяснете с ваши думи как edge computing и CDN работят заедно.          |
| 3 days          | Избройте основните предимства и недостатъци на AI inference на edge.   |
| 1 week          | Нарисувайте архитектура на CDN и обяснете ролята на кеширането.        |
| 1 month         | Дайте пример за реален проблем, решен чрез edge computing или CDN.     |