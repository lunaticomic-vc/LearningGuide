# Supervised_fine_tuning_SFT

## 1. Activate Prior Knowledge
- Какво разбирате под термина „обучение с учител“ (supervised learning) и как се прилага в контекста на изкуствения интелект?
- Каква е разликата между предварително обучение (pretraining) и дообучение (fine-tuning) на модели?
- Как мислите, защо е важно да се адаптира голям езиков модел към конкретна задача или домейн?

## 2. Overview
Supervised Fine-Tuning (SFT) е процесът, при който предварително обучен модел се дообучава върху специфичен набор от данни с етикети, за да подобри представянето си в конкретна задача. Този подход се използва широко при големи езикови модели (Large Language Models, LLMs), за да ги направи по-точни и релевантни за определени приложения, като чатботове, системи за препоръки или автоматичен превод.

SFT е ключова стъпка в изграждането на практически AI системи, защото позволява да се използва вече научената обща информация и да се адаптира към специфични нужди, без да се започва обучението от нулата. Това спестява време, ресурси и подобрява качеството на резултатите.

В по-широката архитектура на AI системите, SFT се намира между предварителното обучение на модела и евентуалното му разгръщане в продукция. Той осигурява мост между общите знания на модела и специфичните изисквания на приложението.

## 3. Key Concepts
- **Supervised Learning (Обучение с учител)** – метод, при който моделът се обучава върху входни данни с известни изходи (етикети), за да научи връзката между тях. Може да се сравни с ученик, който решава задачи с помощта на учител.
- **Fine-Tuning (Дообучение)** – процес на адаптиране на предварително обучен модел към нова задача чрез допълнително обучение върху специфични данни. Представете си го като настройване на инструмент, за да свири по-добре определена мелодия.
- **Pretrained Model (Предварително обучен модел)** – модел, който вече е научил общи характеристики от голям набор от данни, например езикови модели, обучени върху милиарди думи.
- **Loss Function (Функция на загуба)** – мярка за това колко добре моделът предсказва етикетите по време на обучение. Целта е да се минимизира тази стойност.
- **Overfitting (Прекомерно напасване)** – когато моделът се научава твърде добре на тренировъчните данни, но не може да обобщава върху нови, непознати примери. Може да се оприличи на ученик, който запаметява отговорите, без да разбира материала.
- **Epoch (Епоха)** – един пълен цикъл през целия тренировъчен набор от данни по време на обучение.

## 4. Step-by-step Learning Path
1. **Разберете основите на supervised learning**
   - Фокус: Прегледайте концепциите за входни данни, етикети и функция на загуба.
   - Задача: Намерете пример за dataset с етикети (например MNIST) и разгледайте структурата му.
   - Въпроси: Какво представлява етикетът в supervised learning? Защо е важна функцията на загуба?

2. **Запознайте се с предварително обучени модели**
   - Фокус: Разберете какво представлява pretrained модел и защо се използва.
   - Задача: Изтеглете предварително обучен модел (например BERT или GPT) и разгледайте неговата архитектура.
   - Въпроси: Какво научава моделът по време на предварителното обучение? Как това помага при SFT?

3. **Изучете процеса на fine-tuning**
   - Фокус: Разберете как се извършва дообучението върху специфични данни.
   - Задача: Напишете прост скрипт за fine-tuning на предварително обучен модел върху малък dataset.
   - Въпроси: Как се избира learning rate при fine-tuning? Какво е значението на епохите?

4. **Практикувайте избягване на overfitting**
   - Фокус: Научете техники като ранно спиране (early stopping) и регуляризация.
   - Задача: Добавете ранно спиране към вашия fine-tuning скрипт и наблюдавайте резултатите.
   - Въпроси: Какво е overfitting и как може да се избегне? Как ранното спиране помага?

5. **Оценете и валидирайте модела**
   - Фокус: Използвайте метрики за оценка на представянето (accuracy, F1-score).
   - Задача: Изчислете метрики върху тестов набор след fine-tuning.
   - Въпроси: Защо е важно да имаме отделен тестов набор? Какво показва F1-score?

## 5. Examples
### Пример 1: Fine-tuning на BERT за класификация на текст
```python
from transformers import BertForSequenceClassification, Trainer, TrainingArguments, BertTokenizer
from datasets import load_dataset

dataset = load_dataset('imdb')
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def tokenize(batch):
    return tokenizer(batch['text'], padding=True, truncation=True)

dataset = dataset.map(tokenize, batched=True)
dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])

model = BertForSequenceClassification.from_pretrained('bert-base-uncased')

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=8,
    evaluation_strategy="epoch",
    save_strategy="epoch"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset['train'].shuffle().select(range(1000)),
    eval_dataset=dataset['test'].shuffle().select(range(500))
)

trainer.train()
```

### Пример 2: Дообучение GPT-2 за генериране на текст в специфичен стил
```python
from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments
from datasets import load_dataset

dataset = load_dataset('wikitext', 'wikitext-2-raw-v1')
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')

def tokenize_function(examples):
    return tokenizer(examples['text'], truncation=True, max_length=512)

tokenized_datasets = dataset.map(tokenize_function, batched=True)

model = GPT2LMHeadModel.from_pretrained('gpt2')

training_args = TrainingArguments(
    output_dir='./gpt2-finetuned',
    overwrite_output_dir=True,
    num_train_epochs=1,
    per_device_train_batch_size=2,
    save_steps=10_000,
    save_total_limit=2,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets['train']
)

trainer.train()
```

## 6. Common Pitfalls
- **Недостатъчно данни за дообучение** – малък набор от данни може да доведе до overfitting или ниско качество на модела. Решение: използвайте техники за data augmentation или по-големи набори.
- **Прекалено голям learning rate** – може да „разруши“ предварително научените параметри. Решение: започнете с по-нисък learning rate и го настройвайте внимателно.
- **Игнориране на валидиращ набор** – без валидиране не може да се следи overfitting. Решение: винаги разделяйте данните на train/validation/test.
- **Прекалено много епохи** – води до overfitting. Решение: използвайте ранно спиране и наблюдавайте метриките.
- **Неправилна подготовка на данните** – несъответстващи формати или липсващи етикети. Решение: винаги проверявайте качеството и формата на данните преди обучение.

## 7. Short Retrieval Quiz
1. Какво представлява supervised fine-tuning?
2. Защо използваме предварително обучени модели при SFT?
3. Какво е функция на загуба и каква е ролята ѝ?
4. Какво е overfitting и как може да се избегне?
5. Какво означава „epoch“ в контекста на обучение на модели?
6. Защо е важно да имаме валидиращ набор от данни?
7. Какъв е рискът при използване на твърде висок learning rate по време на fine-tuning?

## 8. Quick Recap
- Supervised fine-tuning е дообучение на предварително обучен модел върху специфични етикетирани данни.
- Целта е да се адаптира моделът към конкретна задача, като се използват вече научени общи знания.
- Ключови понятия включват supervised learning, loss function, overfitting и epochs.
- Практическото fine-tuning изисква внимателен избор на learning rate, разделяне на данните и мониторинг на представянето.
- Често срещани грешки са свързани с малки данни, прекалено много епохи и липса на валидиране.
- Оценката на модела след fine-tuning е задължителна за гарантиране на качество и обобщаемост.
- Използването на библиотеки като Hugging Face Transformers улеснява процеса на fine-tuning.

## 9. Spaced Review Plan

| Време след изучаване | Промпти за преговор                                      |
|----------------------|---------------------------------------------------------|
| 1 ден                | Какво е supervised fine-tuning и защо е важен?          |
| 3 дни                | Обяснете ролята на функцията на загуба и overfitting.   |
| 1 седмица            | Опишете стъпките за практическо fine-tuning на модел.  |
| 1 месец              | Прегледайте типични грешки и как да ги избегнете.       |