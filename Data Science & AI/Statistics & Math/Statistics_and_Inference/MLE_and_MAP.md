# MLE_and_MAP

## 1. Activate Prior Knowledge

- Какво знаете за вероятностните модели и тяхната роля в машинното обучение и изкуствения интелект?
- Как бихте оценили параметрите на модел, ако имате само наблюдения, без допълнителна информация?
- Как бихте използвали предварителни знания за параметрите на модел, за да подобрите неговата точност и стабилност?

## 2. Overview

Максималната вероятностна оценка (Maximum Likelihood Estimation, MLE) и максималната апостериорна оценка (Maximum A Posteriori, MAP) са два фундаментални метода за оценка на параметрите в статистическите модели. Те се използват широко в машинното обучение, статистиката и изкуствения интелект за настройване на модели, които описват наблюдаваните данни.

MLE се фокусира върху намирането на параметрите, които максимизират вероятността да наблюдаваме дадените данни, без да се вземат предвид предварителни предположения за параметрите. MAP, от своя страна, комбинира наблюдаваните данни с предварителна информация (prior), което позволява по-стабилна и често по-точна оценка, особено при малки или шумни набори от данни.

Тези методи са ключови за изграждането на надеждни AI системи, тъй като позволяват адаптивно и обосновано настройване на модели, което е основа за прогнозиране, класификация и други задачи.

## 3. Key Concepts

- **Likelihood (Вероятност)** – Мярка за това колко вероятно е да наблюдаваме дадените данни при определени параметри на модела. Мислете за това като за "оценка на съвпадение" между модела и данните.
- **Maximum Likelihood Estimation (MLE)** – Метод за намиране на параметрите, които максимизират вероятността на наблюдаваните данни. Аналогично на намиране на най-добрата настройка на радио, която улавя най-чистия сигнал.
- **Prior (Предварително разпределение)** – Предварителна информация или предположение за параметрите преди да видим данните. Може да се разглежда като "интуиция" или "опит" за параметрите.
- **Posterior (Апостериорно разпределение)** – Актуализирана вероятност за параметрите след като сме видели данните, комбинирайки prior и likelihood.
- **Maximum A Posteriori (MAP)** – Метод за намиране на параметрите, които максимизират апостериорното разпределение, т.е. съчетават prior и likelihood за по-добра оценка.
- **Overfitting (Прекалено нагласяне)** – Когато моделът се адаптира твърде точно към тренировъчните данни, губейки способността да обобщава. MAP често помага за намаляване на този проблем чрез prior.

## 4. Step-by-step Learning Path

1. **Фокус:** Разберете концепцията за likelihood и как се изчислява.
   - **Практическа задача:** Изчислете likelihood за прост модел с нормално разпределение и дадени параметри.
   - **Въпроси за припомняне:** Какво представлява likelihood? Защо е важно да го максимизираме?

2. **Фокус:** Научете как се намира MLE за параметри на модел.
   - **Практическа задача:** Използвайте Python и библиотеката `scipy.optimize` за намиране на MLE на параметри на нормално разпределение.
   - **Въпроси:** Какво означава да максимизираме likelihood? Как MLE се различава от обикновената средна стойност?

3. **Фокус:** Разберете ролята на prior и как се дефинира.
   - **Практическа задача:** Създайте прост prior за параметър (например нормално разпределение) и визуализирайте го.
   - **Въпроси:** Какво е prior? Как prior влияе на оценката?

4. **Фокус:** Изследвайте MAP оценката и как комбинира prior и likelihood.
   - **Практическа задача:** Реализирайте MAP оценка за параметър с даден prior и likelihood.
   - **Въпроси:** Как MAP се различава от MLE? В какви ситуации MAP е по-подходящ?

5. **Фокус:** Приложете MLE и MAP в реален проблем (например класификация или регресия).
   - **Практическа задача:** Използвайте MLE и MAP за обучение на прост байесов класификатор върху малък набор от данни.
   - **Въпроси:** Какви са предимствата на MAP в реални приложения? Как prior може да помогне при малки данни?

## 5. Examples

### Пример 1: MLE за параметри на нормално разпределение

```python
import numpy as np
from scipy.optimize import minimize

data = np.array([2.3, 2.5, 2.1, 2.6, 2.4])

def neg_log_likelihood(params):
    mu, sigma = params[0], params[1]
    n = len(data)
    return 0.5 * n * np.log(2 * np.pi * sigma**2) + np.sum((data - mu)**2) / (2 * sigma**2)

result = minimize(neg_log_likelihood, x0=[0,1], bounds=[(None,None),(1e-5,None)])
mu_mle, sigma_mle = result.x
print(f"MLE estimates: mu = {mu_mle:.3f}, sigma = {sigma_mle:.3f}")
```

### Пример 2: MAP оценка с нормален prior

```python
def neg_log_posterior(params):
    mu, sigma = params[0], params[1]
    prior_mu, prior_sigma = 2.0, 0.5  # prior за mu
    n = len(data)
    likelihood = 0.5 * n * np.log(2 * np.pi * sigma**2) + np.sum((data - mu)**2) / (2 * sigma**2)
    prior = 0.5 * np.log(2 * np.pi * prior_sigma**2) + (mu - prior_mu)**2 / (2 * prior_sigma**2)
    return likelihood + prior

result_map = minimize(neg_log_posterior, x0=[0,1], bounds=[(None,None),(1e-5,None)])
mu_map, sigma_map = result_map.x
print(f"MAP estimates: mu = {mu_map:.3f}, sigma = {sigma_map:.3f}")
```

### Пример 3: Байесов класификатор с MLE и MAP

- Използвайте MLE за оценка на вероятностите на класовете.
- Добавете prior вероятности за класовете и изчислете MAP класификация.

## 6. Common Pitfalls

- **Игнориране на prior при малки данни:** MLE може да доведе до нестабилни оценки, ако данните са малко или шумни. Използвайте MAP с подходящ prior.
- **Неправилно зададен prior:** Ако prior е твърде силен или неправилен, може да изкриви резултатите. Винаги проверявайте и обосновавайте избора на prior.
- **Оптимизация без ограничения:** При оптимизация на likelihood или posterior, неограничените параметри (например дисперсия) могат да доведат до невалидни стойности. Използвайте ограничения.
- **Прекалено доверие в MLE:** MLE не взема предвид несигурността в параметрите, което може да доведе до overfitting.
- **Липса на проверка на конвергенция:** При числени методи за оптимизация, винаги проверявайте дали алгоритъмът е конвергирал.

## 7. Short Retrieval Quiz

1. Какво представлява максималната вероятностна оценка (MLE)?
2. Каква е ролята на prior в MAP оценката?
3. Кога MAP оценката е по-предпочитана пред MLE?
4. Какво е апостериорно разпределение?
5. Как MLE може да доведе до overfitting?
6. Какво е основното различие между likelihood и posterior?
7. Какво трябва да се внимава при оптимизация на параметри?

## 8. Quick Recap

- MLE намира параметрите, които максимизират вероятността на наблюдаваните данни.
- MAP комбинира likelihood с prior, за да даде по-стабилна оценка.
- Prior представлява предварителна информация за параметрите.
- MAP е особено полезен при малки или шумни набори от данни.
- Правилният избор на prior е критичен за качеството на MAP оценката.
- Оптимизацията на likelihood и posterior изисква внимателно управление на ограничения и проверка на конвергенция.
- MLE и MAP са основни инструменти за обучение и настройване на модели в AI и софтуерното инженерство.

## 9. Spaced Review Plan

| Време след учене | Промпт за преговор                                         |
|------------------|------------------------------------------------------------|
| 1 ден            | Обяснете с прости думи разликата между MLE и MAP.          |
| 3 дни            | Опишете ролята на prior в MAP и дайте пример.              |
| 1 седмица        | Напишете кратък код за MLE и MAP оценка на параметър.      |
| 1 месец          | Обсъдете кога и защо бихте избрали MAP пред MLE в проект.   |