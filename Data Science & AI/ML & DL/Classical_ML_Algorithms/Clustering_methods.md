# Clustering_methods

## 1. Activate Prior Knowledge
- Какво представлява групирането на данни и защо би било полезно в системи за изкуствен интелект?
- Можете ли да посочите примери, където автоматичното разделяне на обекти на групи (кластери) би подобрило софтуерно приложение?
- Как бихте различили клъстеризация от класификация в контекста на машинното обучение?

## 2. Overview
Клъстеризацията е техника за групиране на обекти в множество подмножества (кластери), така че обектите в един клъстер да са максимално сходни помежду си, а обектите в различни клъстери – максимално различни. Тя е ключова в анализа на данни, когато липсват предварително зададени етикети, и се използва за откриване на скрити структури в големи обеми информация.

В системите за изкуствен интелект и софтуерното инженерство клъстеризацията служи за предварителна обработка на данни, сегментация на потребители, откриване на аномалии и оптимизация на ресурси. Тя е част от групата на алгоритмите за неконтролирано обучение (unsupervised learning), което я прави особено важна при работа с неетикетирани данни.

Разбирането на различните методи за клъстеризация и техните предимства и ограничения е от съществено значение за изграждането на ефективни AI системи, които могат да се адаптират към различни типове данни и задачи.

## 3. Key Concepts
- **Клъстер (Cluster)** – група от обекти, които са сходни помежду си по определени характеристики. Можем да си го представим като група приятели с общи интереси.
- **Клъстеризация (Clustering)** – процесът на разделяне на набор от обекти на клъстери, без предварително зададени етикети.
- **Центроид (Centroid)** – представителна точка на клъстер, обикновено средната стойност на всички обекти в него. Аналогично на центъра на маса в физиката.
- **Метрика за разстояние (Distance metric)** – функция, която измерва колко са различни два обекта (например Евклидово разстояние).
- **Иерархична клъстеризация (Hierarchical clustering)** – метод, който изгражда дървовидна структура от клъстери чрез последователно сливане или разделяне.
- **K-средни (K-means)** – алгоритъм, който разделя данните на K клъстера, като минимизира сумата на квадратите на разстоянията до центроидите.
- **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** – алгоритъм, който намира клъстери на базата на плътността на точките, откривайки и аномалии.

## 4. Step-by-step Learning Path
1. **Запознайте се с основните понятия и метрики за сходство**
   - Фокус: Евклидово, Манхатънско разстояние и други метрики.
   - Задача: Изчислете разстоянието между няколко точки в двумерно пространство.
   - Въпроси: Какво е разстояние между две точки? Защо изборът на метрика е важен?

2. **Разучете алгоритъма K-средни**
   - Фокус: Инициализация, итеративно обновяване на центроидите.
   - Задача: Имплементирайте K-средни на малък набор от данни.
   - Въпроси: Как се избира броят на клъстерите? Какво се случва при лоша инициализация?

3. **Изследвайте иерархичната клъстеризация**
   - Фокус: Сливане и разделяне на клъстери, dendrogram.
   - Задача: Постройте dendrogram за примерен набор от данни.
   - Въпроси: Какво представлява dendrogram? Как се избира нивото на отрязване?

4. **Запознайте се с плътностно-базирани методи (DBSCAN)**
   - Фокус: Параметри eps и minPts, откриване на шум.
   - Задача: Приложете DBSCAN върху набор с аномалии.
   - Въпроси: Как DBSCAN различава шум от клъстери? Кога е по-подходящ от K-средни?

5. **Практическо приложение и оценка на резултатите**
   - Фокус: Избор на метод според данните, визуализация, метрики за оценка (Silhouette score).
   - Задача: Сравнете резултатите от различни алгоритми върху един и същ набор.
   - Въпроси: Как да оценим качеството на клъстеризация? Какво да направим при лоши резултати?

## 5. Examples

### Пример 1: K-средни с Python (sklearn)
```python
from sklearn.cluster import KMeans
import numpy as np

data = np.array([[1, 2], [1, 4], [1, 0],
                 [10, 2], [10, 4], [10, 0]])

kmeans = KMeans(n_clusters=2, random_state=0).fit(data)
print("Labels:", kmeans.labels_)
print("Centroids:", kmeans.cluster_centers_)
```

### Пример 2: Иерархична клъстеризация и dendrogram
```python
from scipy.cluster.hierarchy import dendrogram, linkage
import matplotlib.pyplot as plt

data = [[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]]
linked = linkage(data, 'single')

dendrogram(linked)
plt.show()
```

### Пример 3: DBSCAN за откриване на аномалии
```python
from sklearn.cluster import DBSCAN
import numpy as np

data = np.array([[1, 2], [2, 2], [2, 3], [8, 7], [8, 8], [25, 80]])
dbscan = DBSCAN(eps=3, min_samples=2).fit(data)
print("Labels:", dbscan.labels_)  # -1 означава шум (аномалия)
```

## 6. Common Pitfalls
- **Избор на неподходящ брой клъстери (K)** – води до лошо групиране; използвайте методи като Elbow или Silhouette.
- **Лоша инициализация на центроидите при K-средни** – може да доведе до локални оптимуми; използвайте K-means++ или няколко старта.
- **Игнориране на скалата на данните** – различните мащаби на характеристиките могат да изкривят разстоянията; нормализирайте данните.
- **Неподходящ избор на метрика за разстояние** – например Евклидово разстояние не е подходящо за категориални данни.
- **Пренебрегване на шум и аномалии** – някои алгоритми не ги откриват, което може да повлияе на резултатите.
- **Прекомерно доверие в визуализации** – визуализацията може да заблуди при високи размерности; използвайте допълнителни метрики.

## 7. Short Retrieval Quiz
1. Какво е основната цел на клъстеризацията?
2. Как се различава K-средни от иерархична клъстеризация?
3. Какво означава центроид в контекста на клъстер?
4. Кога DBSCAN е по-подходящ от K-средни?
5. Защо е важно да нормализираме данните преди клъстеризация?
6. Какво означава стойност -1 в резултатите от DBSCAN?
7. Какви са основните предизвикателства при избора на брой клъстери?

## 8. Quick Recap
- Клъстеризацията групира сходни обекти без предварителни етикети.
- K-средни е популярен, но изисква избор на брой клъстери и нормализирани данни.
- Иерархичната клъстеризация изгражда дървовидна структура, полезна за визуализация.
- DBSCAN открива клъстери на базата на плътност и може да открива аномалии.
- Изборът на метрика и параметри влияе силно на качеството на клъстеризацията.
- Оценката на резултатите е критична за практическото приложение.
- Избягвайте често срещани грешки като лоша инициализация и неподходящи параметри.

## 9. Spaced Review Plan

| Време след учене | Промпт за преглед                                    |
|------------------|-----------------------------------------------------|
| 1 ден            | Обяснете основната идея на K-средни и DBSCAN.       |
| 3 дни            | Опишете разликите между иерархична и плътностна клъстеризация. |
| 1 седмица        | Кога и как бихте избрали метрика за разстояние?      |
| 1 месец          | Приложете клъстеризация върху нов набор от данни и анализирайте резултатите. |