# Attribution_methods

## 1. Activate Prior Knowledge
- Какво разбирате под "атрибуция" в контекста на изкуствения интелект и софтуерното инженерство?
- Можете ли да посочите случаи, в които е важно да разберем кои входни данни или функции са повлияли на изхода на една AI система?
- Как бихте обяснили разликата между "атрибуция" и "интерпретируемост" на модел?

## 2. Overview
Атрибуционните методи са техники, които целят да определят кои части от входните данни или характеристики на модела са най-отговорни за дадено решение или предсказание. Те са ключови за интерпретируемостта на сложни модели, особено дълбоки невронни мрежи, където вътрешната логика не е лесно разбираема.

В по-широк контекст, атрибуцията подпомага доверието в AI системите, позволява откриване на грешки и пристрастия, и улеснява регулаторното съответствие. В софтуерното инженерство тя е част от процеса на анализ и отстраняване на проблеми, както и на оптимизация на модели.

Значението на атрибуционните методи нараства с разпространението на AI в критични области като медицина, финанси и автономни системи, където разбираемостта на решенията е жизненоважна.

## 3. Key Concepts
- **Attribution (Атрибуция)** – процес на определяне на влиянието на отделни входни елементи върху изхода на модела. Може да се сравни с проследяване на причинно-следствени връзки в сложна система.
- **Feature Importance (Важност на характеристиките)** – мярка за това колко дадена характеристика допринася за предсказанието. Аналогично на това да разберем кои съставки в рецепта влияят най-много на вкуса.
- **Saliency Map (Карта на важността)** – визуално представяне, което показва кои части от входа (например пиксели в изображение) са най-значими за решението на модела.
- **Gradient-based Attribution (Атрибуция на базата на градиенти)** – метод, който използва производните на изхода спрямо входа, за да определи влиянието на всеки входен елемент.
- **SHAP (SHapley Additive exPlanations)** – метод, базиран на теорията на игрите, който разпределя "печалбата" (предсказанието) между входните характеристики по справедлив начин.
- **LIME (Local Interpretable Model-agnostic Explanations)** – локален метод, който създава опростен модел около конкретно предсказание, за да обясни поведението му.

## 4. Step-by-step Learning Path
1. **Фокус:** Основи на атрибуцията и защо е нужна.  
   **Задача:** Прочетете и обобщете статия за значението на интерпретируемостта в AI.  
   **Въпроси:** Какво е атрибуция? Защо е важна в AI системите?

2. **Фокус:** Запознаване с базови методи като градиентна атрибуция.  
   **Задача:** Имплементирайте прост градиентен атрибуционен метод върху предварително обучен невронен модел за класификация на изображения.  
   **Въпроси:** Как градиентите показват важността на входа? Какво означава голям градиент?

3. **Фокус:** Изучаване на SHAP и LIME.  
   **Задача:** Използвайте библиотеките SHAP и LIME върху таблични данни, за да обясните предсказания на модел.  
   **Въпроси:** Как SHAP разпределя важността? Как LIME създава локален модел?

4. **Фокус:** Визуализация и интерпретация на резултатите.  
   **Задача:** Създайте визуализации на атрибуцията и анализирайте резултатите спрямо реални данни.  
   **Въпроси:** Какви са предимствата на визуалните обяснения? Как да разпознаем грешки в атрибуцията?

5. **Фокус:** Приложения и ограничения на атрибуционните методи.  
   **Задача:** Напишете кратко есе за потенциалните капани при използване на атрибуционни методи в реални проекти.  
   **Въпроси:** Кои са основните ограничения на атрибуцията? Как да ги минимизираме?

## 5. Examples
### Пример 1: Градиентна атрибуция върху изображение с TensorFlow/Keras
```python
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

model = tf.keras.applications.MobileNetV2(weights='imagenet')
img = tf.keras.preprocessing.image.load_img('cat.jpg', target_size=(224, 224))
input_arr = tf.keras.preprocessing.image.img_to_array(img)
input_arr = np.expand_dims(input_arr, axis=0)
input_arr = tf.keras.applications.mobilenet_v2.preprocess_input(input_arr)

with tf.GradientTape() as tape:
    tape.watch(input_arr)
    preds = model(input_arr)
    top_pred_index = tf.argmax(preds[0])
    top_class_channel = preds[:, top_pred_index]

grads = tape.gradient(top_class_channel, input_arr)[0]
plt.imshow(np.sum(np.abs(grads), axis=-1), cmap='viridis')
plt.title('Gradient-based Attribution Map')
plt.show()
```

### Пример 2: SHAP за обяснение на модел за таблични данни
```python
import shap
import xgboost
import pandas as pd

X, y = shap.datasets.adult()
model = xgboost.XGBClassifier().fit(X, y)
explainer = shap.Explainer(model, X)
shap_values = explainer(X.iloc[:10])

shap.plots.bar(shap_values)
```

### Пример 3: LIME за локално обяснение на текстов модел
```python
from lime.lime_text import LimeTextExplainer
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

texts = ["This movie is great!", "I did not like the film."]
labels = [1, 0]

vectorizer = TfidfVectorizer()
classifier = LogisticRegression()
pipeline = make_pipeline(vectorizer, classifier)
pipeline.fit(texts, labels)

explainer = LimeTextExplainer(class_names=['negative', 'positive'])
exp = explainer.explain_instance(texts[0], pipeline.predict_proba, num_features=3)
exp.show_in_notebook()
```

## 6. Common Pitfalls
- **Интерпретиране на атрибуцията като абсолютна истина:** Атрибуционните методи дават приближени оценки, не гарантират точна причинно-следствена връзка. Винаги ги разглеждайте критично.
- **Игнориране на контекста:** Важността на характеристиките може да варира в различни части на входа или при различни примери. Локалните методи като LIME са по-подходящи за това.
- **Прекалено опростяване:** Някои методи могат да загубят информация или да въведат шум при опростяване на сложни модели.
- **Зависимост от модела:** Някои атрибуционни методи са специфични за определени архитектури и не са универсални.
- **Пренебрегване на визуализацията:** Без визуална проверка лесно се пропускат аномалии или грешки в атрибуцията.

## 7. Short Retrieval Quiz
1. Какво представлява атрибуцията в AI моделите?  
2. Коя е основната идея зад градиентната атрибуция?  
3. Как SHAP методът разпределя важността между характеристиките?  
4. Защо LIME е наречен "локален" метод?  
5. Каква е разликата между атрибуция и интерпретируемост?  
6. Какви са потенциалните рискове при използване на атрибуционни методи?  
7. Как визуализациите подпомагат разбирането на атрибуцията?

## 8. Quick Recap
- Атрибуционните методи определят влиянието на входните характеристики върху изхода на AI модел.
- Те са ключови за интерпретируемост, доверие и откриване на грешки.
- Основни методи включват градиентна атрибуция, SHAP и LIME.
- Визуализацията помага да се разбере и анализира резултатът.
- Методите имат ограничения и трябва да се използват внимателно.
- Локалните обяснения са полезни за конкретни предсказания, а глобалните – за общо поведение.
- Практическото приложение изисква разбиране на теорията и критичен анализ на резултатите.

## 9. Spaced Review Plan

| Време след учене | Промпти за преговор                                         |
|-------------------|-------------------------------------------------------------|
| 1 ден             | Какво е атрибуция и защо е важна? Опишете основните методи. |
| 3 дни             | Обяснете разликите между SHAP и LIME с примери.             |
| 1 седмица         | Как визуализацията подпомага анализа на атрибуцията?        |
| 1 месец           | Кои са основните ограничения на атрибуционните методи? Как да ги избегнем? |