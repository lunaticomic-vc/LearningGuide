# Underfitting_vs_overfitting

## 1. Activate Prior Knowledge
- Какво разбирате под „обучение на модел“ в контекста на изкуствен интелект и машинно обучение?
- Как мислите, че моделът може да се справи с нови, непознати данни след обучението?
- Как бихте описали разликата между „прекалено опростен“ и „прекалено сложен“ модел?

## 2. Overview
В машинното обучение и изкуствения интелект, целта е да се създаде модел, който да обобщава правилно данните, а не просто да ги запомня. Това означава, че моделът трябва да се справя добре не само с данните, върху които е обучен, но и с нови, непознати примери. Проблемите с поднастройването (underfitting) и пренастройването (overfitting) са основни препятствия за постигане на тази цел.

Поднастройването се случва, когато моделът е твърде прост, за да улови сложността на данните, и затова не успява да се представи добре дори върху обучаващия набор. От друга страна, пренастройването се появява, когато моделът е твърде сложен и запомня шума и детайлите в обучаващите данни, което води до лоша генерализация върху нови данни.

Разбирането на тези феномени е ключово за изграждането на надеждни AI системи и за избора на правилните техники за обучение, валидиране и тестване на модели.

## 3. Key Concepts
- **Underfitting (Поднастройване)** – Модел, който не успява да улови основните зависимости в данните, подобно на ученик, който не разбира материала и затова дава грешни отговори дори на прости въпроси.
- **Overfitting (Пренастройване)** – Модел, който „запомня“ обучаващите данни прекалено добре, включително и шума, като ученик, който учи наизуст, но не разбира концепциите и се затруднява с нови въпроси.
- **Bias (Изкривяване)** – Систематична грешка, която води до поднастройване; моделът е твърде опростен, за да улови истинските зависимости.
- **Variance (Вариация)** – Колебания в предсказанията на модела при различни обучаващи набори, свързани с пренастройването.
- **Generalization (Генерализация)** – Способността на модела да се представя добре върху нови, непознати данни.
- **Training set, Validation set, Test set (Обучаващ, Валидиращ, Тестов набор)** – Разделяне на данните за различни етапи на обучение и оценка, което помага да се открие поднастройване и пренастройване.

## 4. Step-by-step Learning Path
1. **Фокус:** Разберете какво е поднастройване и пренастройване.  
   **Задача:** Използвайте прост модел (напр. линейна регресия) върху малък набор от данни и наблюдавайте резултатите.  
   **Въпроси:** Как се променя грешката върху обучаващия и тестовия набор? Кога моделът изглежда поднастроен?

2. **Фокус:** Изучете ролята на сложността на модела.  
   **Задача:** Сравнете резултатите на модели с различна сложност (напр. линейна регресия срещу полиномиална регресия).  
   **Въпроси:** Как сложността влияе на bias и variance? Кога се появява пренастройване?

3. **Фокус:** Използване на техники за предотвратяване на пренастройване.  
   **Задача:** Прилагайте регуляризация (L1, L2) и крос-валидация върху същия набор от данни.  
   **Въпроси:** Как регуляризацията влияе на представянето? Какво е крос-валидация и защо помага?

4. **Фокус:** Оценка на генерализацията.  
   **Задача:** Разделете данните на обучаващ, валидиращ и тестов набор и измерете грешките.  
   **Въпроси:** Каква е разликата между грешките върху различните набори? Как да разпознаем поднастройване и пренастройване?

5. **Фокус:** Прилагане на знанията в реален проект.  
   **Задача:** Изберете реален набор от данни и изградете модел, който балансира bias и variance.  
   **Въпроси:** Какви техники използвахте за избягване на поднастройване и пренастройване? Как оценихте успеха?

## 5. Examples

### Пример 1: Линейна регресия с поднастройване
```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np

# Синтетични данни с нелинейна зависимост
X = np.linspace(0, 10, 100).reshape(-1, 1)
y = np.sin(X).ravel() + np.random.normal(0, 0.1, 100)

model = LinearRegression()
model.fit(X, y)
predictions = model.predict(X)

print("MSE:", mean_squared_error(y, predictions))
```
Тук линейният модел не може да улови синусоидалната форма, което води до поднастройване.

### Пример 2: Полиномиална регресия с пренастройване
```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

poly_model = make_pipeline(PolynomialFeatures(degree=15), LinearRegression())
poly_model.fit(X, y)
predictions_poly = poly_model.predict(X)

print("MSE:", mean_squared_error(y, predictions_poly))
```
Твърде високата степен на полинома води до пренастройване – моделът следва шума в данните.

### Пример 3: Регуляризация за контрол на пренастройването
```python
from sklearn.linear_model import Ridge

ridge_model = Ridge(alpha=1.0)
ridge_model.fit(X, y)
predictions_ridge = ridge_model.predict(X)

print("MSE:", mean_squared_error(y, predictions_ridge))
```
Регуляризацията намалява сложността и подобрява генерализацията.

## 6. Common Pitfalls
- **Игнориране на разделението на данните:** Обучение и тестване върху едни и същи данни води до подвеждащи резултати.
- **Избор на прекалено сложен модел без контрол:** Водещо до пренастройване и лоша генерализация.
- **Прекалена опростеност на модела:** Поднастройване, което не позволява да се уловят важни зависимости.
- **Пренебрегване на валидиращ набор:** Без него е трудно да се открие пренастройване.
- **Неправилна употреба на регуляризация:** Твърде силна регуляризация може да доведе до поднастройване.

## 7. Short Retrieval Quiz
1. Какво представлява поднастройването?
2. Какво е пренастройване и как се проявява?
3. Каква е ролята на bias и variance в модела?
4. Защо е важно да имаме отделен валидиращ набор?
5. Как регуляризацията помага при пренастройване?
6. Как можем да разпознаем, че моделът е пренастроен?
7. Какво означава генерализация в контекста на машинното обучение?

## 8. Quick Recap
- Поднастройването е резултат от твърде прост модел, който не улавя сложността на данните.
- Пренастройването е когато моделът е твърде сложен и запомня шума в обучаващите данни.
- Балансът между bias и variance е ключов за добра генерализация.
- Разделянето на данните на обучаващ, валидиращ и тестов набор е критично.
- Регуляризацията и крос-валидацията са основни техники за контрол на пренастройването.
- Оценката на модела върху непознати данни е най-добрият начин да проверим генерализацията.
- Практическото разбиране на тези концепции е фундаментално за изграждане на надеждни AI системи.

## 9. Spaced Review Plan

| Време след първоначалното учене | Промпт за преглед                                      |
|-------------------------------|-------------------------------------------------------|
| 1 ден                         | Обяснете с прости думи разликата между underfitting и overfitting. |
| 3 дни                         | Дайте пример за техника, която помага да се избегне пренастройване. |
| 1 седмица                     | Опишете как bias и variance влияят на представянето на модела.     |
| 1 месец                      | Прегледайте стъпките за изграждане на модел с добра генерализация. |