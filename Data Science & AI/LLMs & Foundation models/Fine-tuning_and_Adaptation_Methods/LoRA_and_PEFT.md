# LoRA_and_PEFT

## 1. Activate Prior Knowledge
- Какво знаете за трансферното обучение и как то помага за адаптиране на големи модели в изкуствения интелект?
- Какви са предизвикателствата при фина настройка на големи невронни мрежи, особено по отношение на изчислителните ресурси и паметта?
- Как бихте оптимизирали обучение на модел, когато разполагате с ограничени данни или ограничени хардуерни възможности?

## 2. Overview
LoRA (Low-Rank Adaptation) и PEFT (Parameter-Efficient Fine-Tuning) са съвременни техники за ефективна фина настройка на големи езикови и други модели. Целта им е да позволят адаптиране на предварително обучени модели с минимални промени в параметрите, което намалява изискванията за памет и време за обучение.

Тези методи се използват широко в контекста на големи трансформър модели, където пълната фина настройка е често непрактична поради размера на модела и ресурсните ограничения. LoRA постига това чрез въвеждане на нискорангови матрици, които се учат, докато основните параметри остават фиксирани. PEFT е по-общ термин, който включва LoRA и други подобни методи за параметър-ефикасно обучение.

Тези подходи са ключови за разработването на персонализирани AI системи, които могат да се адаптират към специфични задачи или домейни без необходимост от повторно обучение на целия модел. Това ускорява иновациите и намалява разходите.

## 3. Key Concepts
- **LoRA (Low-Rank Adaptation)** – метод за адаптация на големи модели чрез въвеждане на нискорангови матрици, които се обучават, докато основните параметри остават замразени. Аналогия: добавяне на малки, ефективни „надстройки“ върху голяма машина.
- **PEFT (Parameter-Efficient Fine-Tuning)** – общ подход за фина настройка, който използва минимален брой параметри за обучение, за да се постигне адаптация без пълно преобучение.
- **Rank (ранг)** – мярка за размерността на матрица; нискоранговите матрици имат по-малка размерност, което намалява броя на параметрите.
- **Frozen Parameters (замразени параметри)** – параметри на модела, които не се променят по време на фина настройка, за да се запази основното знание.
- **Adapter Layers (адаптер слоеве)** – допълнителни слоеве, които се добавят към модела и се обучават, докато останалата част от модела остава фиксирана.
- **Fine-Tuning (фина настройка)** – процес на допълнително обучение на предварително обучен модел върху нови данни за специфична задача.

## 4. Step-by-step Learning Path
1. **Разберете основите на трансформър архитектурата и фина настройка**
   - Задача: Прочетете и обобщете основните компоненти на трансформър модел.
   - Въпроси: Какво представлява вниманието (attention) в трансформър? Защо фина настройка е важна?
2. **Изучете принципите на нискоранговата аппроксимация**
   - Задача: Направете малък експеримент с матрици, като ги апроксимирайте с нискорангови факторизации.
   - Въпроси: Какво е предимството на нискоранговата аппроксимация? Как тя намалява параметрите?
3. **Запознайте се с LoRA и как се интегрира в трансформър модели**
   - Задача: Прегледайте примерен код за LoRA и обяснете как се добавят нискорангови матрици.
   - Въпроси: Кои параметри се обучават при LoRA? Какво остава замразено?
4. **Практикувайте PEFT с различни техники (LoRA, Adapter Layers)**
   - Задача: Използвайте библиотека като Hugging Face PEFT, за да приложите LoRA върху предварително обучен модел.
   - Въпроси: Какви са предимствата на PEFT спрямо пълната фина настройка? Какви ресурси спестявате?
5. **Оценете ефективността и ограниченията на LoRA и PEFT**
   - Задача: Сравнете резултатите и ресурсните изисквания между пълна фина настройка и PEFT.
   - Въпроси: Кога PEFT може да не е подходящ? Какви компромиси се правят?

## 5. Examples

### Пример 1: Добавяне на LoRA към трансформър слой (псевдокод)
```python
class LoRALayer(nn.Module):
    def __init__(self, original_layer, rank=4):
        super().__init__()
        self.original_layer = original_layer
        self.lora_A = nn.Linear(original_layer.in_features, rank, bias=False)
        self.lora_B = nn.Linear(rank, original_layer.out_features, bias=False)
        # Замразяваме оригиналния слой
        for param in self.original_layer.parameters():
            param.requires_grad = False

    def forward(self, x):
        return self.original_layer(x) + self.lora_B(self.lora_A(x))
```

### Пример 2: Използване на Hugging Face PEFT библиотека за LoRA
```python
from transformers import AutoModelForSeq2SeqLM
from peft import get_peft_model, LoraConfig

model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")
lora_config = LoraConfig(r=8, lora_alpha=32, target_modules=["q", "v"])
model = get_peft_model(model, lora_config)

# Обучение само на LoRA параметрите
```

### Пример 3: Сравнение на параметри
- Пълна фина настройка: 220M параметри
- LoRA с rank=8: ~1-2M параметри за обучение

## 6. Common Pitfalls
- **Опит за фина настройка на всички параметри при ограничени ресурси** – води до бавно обучение и изчерпване на паметта. Решение: използвайте PEFT.
- **Избор на твърде висок ранг (rank) в LoRA** – увеличава броя на параметрите и губи предимствата на метода.
- **Неправилно замразяване на параметри** – ако основните параметри не са замразени, моделът се обучава пълноценно, губейки ефективността.
- **Игнориране на съвместимостта с конкретния модел** – LoRA трябва да се прилага към подходящи слоеве (например attention слоеве).
- **Недостатъчно валидиране на адаптиран модел** – важно е да се тества дали адаптацията подобрява представянето по целевата задача.

## 7. Short Retrieval Quiz
1. Какво означава LoRA и каква е основната му идея?
2. Как PEFT намалява нуждата от ресурси при фина настройка?
3. Какво представлява „замразяване на параметри“ и защо е важно?
4. Кой параметър контролира размерността на нискоранговата аппроксимация в LoRA?
5. Какви са предимствата на използването на LoRA спрямо пълната фина настройка?
6. Кои слоеве на трансформър модел обикновено се адаптират с LoRA?
7. Какво може да се случи, ако не замразите основните параметри при използване на LoRA?

## 8. Quick Recap
- LoRA и PEFT са техники за параметър-ефикасна фина настройка на големи модели.
- LoRA използва нискорангови матрици, които се обучават, докато основните параметри остават замразени.
- PEFT включва различни методи за адаптация с малко параметри, което намалява изискванията за памет и време.
- Тези методи са критични за персонализиране на големи модели при ограничени ресурси.
- Важно е правилно да се замразят параметрите и да се избере подходящ ранг.
- Практическото приложение включва използване на библиотеки като Hugging Face PEFT.
- Честите грешки включват прекалено голям ранг и непълно замразяване на параметри.

## 9. Spaced Review Plan

| Време след учене | Преговорен въпрос                                             |
|-------------------|---------------------------------------------------------------|
| 1 ден             | Какво е LoRA и как работи нискоранговата адаптация?           |
| 3 дни             | Как PEFT оптимизира фина настройка спрямо пълното обучение?   |
| 1 седмица         | Кои параметри се обучават и кои се замразяват при LoRA?       |
| 1 месец           | Какви са основните предимства и ограничения на LoRA и PEFT?   |