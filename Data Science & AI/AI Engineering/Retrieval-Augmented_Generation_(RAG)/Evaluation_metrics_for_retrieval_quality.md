# Evaluation_metrics_for_retrieval_quality

## 1. Activate Prior Knowledge

- Какво представлява системата за информационно извличане (Information Retrieval) и какви задачи решава?
- Защо е важно да оценяваме качеството на резултатите, които връща търсещата система?
- Как бихте измерили дали дадена търсачка връща "добри" резултати за потребителя?

## 2. Overview

Оценката на качеството на системите за извличане на информация е критичен етап в разработката и подобряването на търсещи машини, препоръчителни системи и други AI приложения, които връщат списъци с релевантна информация. Тези метрики ни позволяват да измерим колко добре системата изпълнява своята задача – да намери и подреди най-подходящите документи спрямо заявката на потребителя.

В по-широк контекст, оценката на качеството на извличане е част от цикъла на разработка на софтуер, където резултатите се използват за оптимизиране на алгоритми, сравнение между модели и гарантиране на удовлетвореността на крайния потребител. Без надеждни метрики, подобренията биха били произволни и неефективни.

Тези метрики са особено важни в контекста на AI, където системите често работят с големи обеми данни и сложни модели. Те ни дават количествени показатели, които могат да се използват за автоматично обучение, тестване и валидиране на системата.

## 3. Key Concepts

- **Precision (Точност)** – Процентът на върнатите резултати, които са релевантни. Аналогия: от всички книги, които си взел от библиотеката, колко са наистина полезни за твоята тема?
- **Recall (Пълнота)** – Процентът на всички релевантни резултати, които системата е успяла да върне. Аналогия: колко от всички полезни книги в библиотеката си успял да намериш?
- **F1 Score** – Хармонично средно между точност и пълнота, което балансира двата аспекта в една метрика.
- **Mean Average Precision (MAP)** – Средната стойност на точността, изчислена при всяка позиция, където има релевантен резултат. Полезна за оценка на подредбата на резултатите.
- **Normalized Discounted Cumulative Gain (NDCG)** – Метрика, която отчита позицията на релевантните резултати, като дава по-голяма тежест на по-горните позиции в списъка.
- **ROC и AUC** – Метрики, използвани при бинарна класификация, които могат да се адаптират за оценка на ранжиране.
- **Relevance (Релевантност)** – Степента, до която даден резултат отговаря на нуждите на потребителя.

## 4. Step-by-step Learning Path

1. **Фокус:** Разбиране на основните метрики Precision и Recall  
   **Задача:** Изчислете точността и пълнотата за даден малък набор от резултати (например 10 върнати документа, от които 6 са релевантни, а общо релевантните документи са 8).  
   **Въпроси:** Какво означава висока точност? Какво означава висока пълнота?

2. **Фокус:** Балансиране на Precision и Recall чрез F1 Score  
   **Задача:** Изчислете F1 score за същия набор от данни.  
   **Въпроси:** Защо F1 score е полезен? Кога може да е по-подходящ от самостоятелната точност или пълнота?

3. **Фокус:** Изучаване на метрики за ранжиране – MAP и NDCG  
   **Задача:** Изчислете MAP и NDCG за примерен списък с резултати, като използвате релевантност с различни степени (например 0, 1, 2).  
   **Въпроси:** Как NDCG отчита позицията на резултатите? Защо това е важно?

4. **Фокус:** Практическо прилагане в код  
   **Задача:** Използвайте Python библиотека (например scikit-learn или pytrec_eval) за изчисляване на метрики върху реален набор от данни.  
   **Въпроси:** Какви предизвикателства срещате при прилагането на метриките? Как да интерпретирате резултатите?

5. **Фокус:** Анализ на trade-offs и избор на метрика според конкретен случай  
   **Задача:** Направете кратък анализ кога бихте предпочели да оптимизирате за точност, а кога за пълнота.  
   **Въпроси:** Какви са последствията от избора на метрика за крайния потребител?

## 5. Examples

### Пример 1: Изчисляване на Precision и Recall

```python
retrieved_docs = ['doc1', 'doc2', 'doc3', 'doc4', 'doc5']
relevant_docs = ['doc2', 'doc4', 'doc6', 'doc7']

true_positives = len(set(retrieved_docs) & set(relevant_docs))
precision = true_positives / len(retrieved_docs)
recall = true_positives / len(relevant_docs)

print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
```

### Пример 2: Използване на sklearn за F1 score

```python
from sklearn.metrics import f1_score

y_true = [1, 0, 1, 1, 0, 1, 0]
y_pred = [1, 0, 1, 0, 0, 1, 1]

score = f1_score(y_true, y_pred)
print(f"F1 Score: {score:.2f}")
```

### Пример 3: Изчисляване на NDCG с pytrec_eval

```python
import pytrec_eval

qrel = {'q1': {'doc1': 3, 'doc2': 2, 'doc3': 0}}
run = {'q1': {'doc2': 1, 'doc3': 2, 'doc1': 3}}

evaluator = pytrec_eval.RelevanceEvaluator(qrel, {'ndcg'})
results = evaluator.evaluate(run)

print(f"NDCG: {results['q1']['ndcg']:.3f}")
```

## 6. Common Pitfalls

- **Игнориране на контекста на приложението:** Не всички метрики са подходящи за всяка задача. Например, висока точност може да е по-важна от пълнотата в медицински приложения.
- **Фокус само върху една метрика:** Оптимизирането само за една метрика може да доведе до влошаване на другите аспекти на качеството.
- **Неправилно определяне на релевантност:** Липсата на ясни критерии за релевантност води до неточни оценки.
- **Пренебрегване на ранжиране:** Метрики като точност и пълнота не отчитат позицията на резултатите, което е критично за потребителското изживяване.
- **Липса на достатъчно тестови данни:** Малки и непредставителни тестови набори могат да доведат до подвеждащи резултати.

## 7. Short Retrieval Quiz

1. Какво измерва метриката Precision?
2. Каква е разликата между Precision и Recall?
3. Защо F1 Score е полезен при оценка на системи за извличане?
4. Какво означава NDCG и какво отчита тя?
5. Кога е по-важно да се оптимизира Recall вместо Precision?
6. Какво представлява релевантността в контекста на информационно извличане?
7. Каква е опасността от оптимизиране само за една метрика?

## 8. Quick Recap

- Оценката на качеството на извличане е ключова за подобряване на търсещи системи и AI приложения.
- Precision и Recall измерват точността и пълнотата на върнатите резултати.
- F1 Score балансира между точност и пълнота.
- Метрики като MAP и NDCG отчитат не само релевантността, но и позицията на резултатите.
- Изборът на метрика зависи от конкретния контекст и целите на приложението.
- Практическото изчисляване на метрики изисква правилно дефиниране на релевантност и подходящи тестови данни.
- Избягвайте да се фокусирате само върху една метрика и винаги анализирайте trade-offs.

## 9. Spaced Review Plan

| Време след изучаване | Промпт за преговор                                      |
|----------------------|---------------------------------------------------------|
| 1 ден                | Обяснете разликата между Precision и Recall с пример.  |
| 3 дни                | Изчислете F1 score за даден набор от резултати.        |
| 1 седмица            | Опишете кога и защо да използвате NDCG при оценка.     |
| 1 месец              | Анализирайте trade-offs между различни метрики в проект.|