# Categorical_encoding

## 1. Activate Prior Knowledge
- Какво представляват категориалните променливи и защо не могат да се използват директно в повечето машинно-обучителни алгоритми?
- Какви са някои от начините, по които данните могат да бъдат преобразувани, за да станат пригодни за моделиране?
- Как бихте подходили към обработката на текстови или номинални данни в софтуерна система за изкуствен интелект?

## 2. Overview
Категориалното кодиране е процесът на преобразуване на категориални (номинални или ординални) данни в числов формат, който може да бъде използван от алгоритми за машинно обучение и други аналитични инструменти. Тъй като повечето модели изискват числови входни данни, категорийните променливи трябва да бъдат трансформирани по начин, който запазва тяхната семантика и структура.

Този процес е ключов етап в подготовката на данните (data preprocessing) и влияе директно върху качеството и ефективността на модела. Неправилното кодиране може да доведе до загуба на информация, изкривяване на връзките между променливите или дори до лоша производителност на модела.

Категориалното кодиране се използва широко в системи за препоръки, обработка на естествен език, финансови модели и други области, където данните съдържат текстови или дискретни стойности. Важно е да се разберат различните техники и кога да се прилагат, за да се оптимизира процесът на обучение и прогнозиране.

## 3. Key Concepts
- **Категориална променлива** – променлива, която приема стойности от фиксиран набор от категории, например цветове, държави или типове продукти. Може да бъде номинална (без вътрешен ред) или ординална (с ред).
- **One-Hot Encoding** – метод, при който всяка категория се представя чрез бинарен вектор с 1 на позицията на категорията и 0 на останалите. Аналогия: като да имаш множество превключватели, от които само един е включен.
- **Label Encoding** – всяка категория се заменя с уникално цяло число. Подходящо за ординални данни, но може да въведе неочакван ред.
- **Target Encoding** – заместване на категориите с числови стойности, базирани на целевата променлива (например средна стойност на таргета за всяка категория). Използва се за подобряване на представянето, но крие риск от overfitting.
- **Dummy Variable Trap** – ситуация, при която една от колоните в one-hot кодираните данни може да бъде линейно предсказана от останалите, водеща до мултиколинеарност.
- **High Cardinality** – ситуация, когато категориалната променлива има много уникални стойности, което затруднява традиционното кодиране и изисква специални техники.

## 4. Step-by-step Learning Path
1. **Разбиране на категориалните променливи**
   - Фокус: Определяне на типовете категориални данни (номинални, ординални).
   - Задача: Изберете набор от данни и идентифицирайте категориалните променливи.
   - Въпроси: Каква е разликата между номинална и ординална променлива? Защо е важно да се прави тази разлика?

2. **Изучаване на основните методи за кодиране**
   - Фокус: One-Hot и Label Encoding.
   - Задача: Приложете и двата метода върху избраните категориални променливи с помощта на Python (pandas, scikit-learn).
   - Въпроси: Кога е подходящо да използваме Label Encoding? Какво представлява Dummy Variable Trap?

3. **Работа с high cardinality**
   - Фокус: Проблеми и техники при голям брой категории.
   - Задача: Използвайте Target Encoding или Hashing Encoding върху категориална променлива с много уникални стойности.
   - Въпроси: Какво е предимството на Target Encoding? Какви са рисковете?

4. **Интеграция в ML pipeline**
   - Фокус: Включване на кодиращите методи в процеса на обучение и тестване.
   - Задача: Създайте pipeline с sklearn, който автоматично кодира категориалните данни и тренира модел.
   - Въпроси: Защо е важно кодиращите трансформации да се прилагат последователно и по същия начин върху тренировъчния и тестовия сет?

5. **Оценка и оптимизация**
   - Фокус: Анализ на влиянието на различните кодирания върху резултатите.
   - Задача: Сравнете производителността на моделите с различни кодиращи техники.
   - Въпроси: Как да изберем най-подходящия метод за даден проблем? Какво е влиянието на overfitting при Target Encoding?

## 5. Examples

### Пример 1: One-Hot Encoding с pandas
```python
import pandas as pd

data = pd.DataFrame({'Цвят': ['червен', 'син', 'зелен', 'червен']})
one_hot = pd.get_dummies(data['Цвят'])
print(one_hot)
```

### Пример 2: Label Encoding с scikit-learn
```python
from sklearn.preprocessing import LabelEncoder

data = ['малък', 'среден', 'голям', 'среден']
le = LabelEncoder()
encoded = le.fit_transform(data)
print(encoded)  # Изход: [1 2 0 2]
```

### Пример 3: Target Encoding с category_encoders
```python
import pandas as pd
import category_encoders as ce

df = pd.DataFrame({
    'Град': ['София', 'Пловдив', 'София', 'Варна'],
    'Продажби': [200, 150, 300, 100]
})

encoder = ce.TargetEncoder(cols=['Град'])
df['Град_encoded'] = encoder.fit_transform(df['Град'], df['Продажби'])
print(df)
```

## 6. Common Pitfalls
- **Използване на Label Encoding за номинални данни** – може да въведе неестествен ред, който моделът да интерпретира като числова зависимост.
- **Пропускане на Dummy Variable Trap** – при one-hot encoding трябва да се премахне една колона, за да се избегне мултиколинеарност.
- **Overfitting при Target Encoding** – ако не се използват техники като крос-валидация или регуляризация, моделът може да се научи на шум.
- **Игнориране на unseen категории при тестови данни** – нови категории, които не са били в тренировъчния сет, могат да доведат до грешки.
- **Неправилно прилагане на трансформации в pipeline** – трансформациите трябва да се тренират само на тренировъчните данни и да се прилагат същите на тестовите.

## 7. Short Retrieval Quiz
1. Какво е категориална променлива?
2. Кога е подходящо да използваме One-Hot Encoding?
3. Какъв е рискът при използване на Label Encoding за номинални данни?
4. Какво представлява Dummy Variable Trap?
5. Защо Target Encoding може да доведе до overfitting?
6. Как да се справим с нови категории при тестови данни?
7. Какво е high cardinality и какво предизвиква?

## 8. Quick Recap
- Категориалното кодиране преобразува текстови или дискретни категории в числови данни.
- Основните методи са One-Hot Encoding и Label Encoding, всеки с предимства и ограничения.
- Target Encoding е мощен, но изисква внимателна употреба за избягване на overfitting.
- Високата кардиналност изисква специални техники за ефективно кодиране.
- Правилното кодиране е критично за качеството на машинно-обучителните модели.
- Трансформациите трябва да се прилагат последователно и консистентно в целия ML pipeline.
- Често срещани грешки включват неправилно кодиране и липса на обработка на unseen категории.

## 9. Spaced Review Plan

| Време след учене | Промпт за преговор                                      |
|------------------|--------------------------------------------------------|
| 1 ден            | Обяснете разликата между One-Hot и Label Encoding.     |
| 3 дни            | Кои са рисковете при Target Encoding и как да ги избегнем? |
| 1 седмица        | Как да се справим с high cardinality в категориалните данни? |
| 1 месец          | Прегледайте целия ML pipeline с категориално кодиране и обяснете защо е важен. |