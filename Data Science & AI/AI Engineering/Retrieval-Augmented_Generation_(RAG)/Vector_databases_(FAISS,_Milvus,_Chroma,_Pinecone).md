# Vector_databases_(FAISS,_Milvus,_Chroma,_Pinecone)

## 1. Activate Prior Knowledge

- Какво представляват векторите и как се използват за представяне на данни в съвременните AI системи?
- Защо търсенето на сходни обекти в големи множества от данни е предизвикателство и какви са традиционните подходи за решаването му?
- Как мислите, че специализирани бази данни за вектори могат да подобрят ефективността и мащабируемостта на AI приложенията?

## 2. Overview

Векторните бази данни са специализирани системи, оптимизирани за съхранение, индексиране и търсене на векторни представяния на данни. В контекста на AI, много типове данни — като текст, изображения и аудио — се преобразуват във вектори, които улавят семантична информация. Тези бази данни позволяват бързо и ефективно намиране на най-близките съседи (nearest neighbors) в многомерни пространства, което е ключово за задачи като препоръчване, класификация и извличане на информация.

FAISS, Milvus, Chroma и Pinecone са четири популярни решения с различни архитектури и функционалности. FAISS е библиотека с отворен код, фокусирана върху бързото търсене на вектори на локален хардуер. Milvus предоставя мащабируема платформа с поддръжка за разпределени среди и множество индексиращи алгоритми. Chroma е по-нов проект, ориентиран към интеграция с LLM и управление на embeddings. Pinecone е облачна услуга, предлагаща лесна интеграция и автоматично управление на инфраструктурата.

Тези системи са критични компоненти в съвременните AI стекове, тъй като позволяват ефективно търсене и анализ на големи обеми от семантични данни, което е невъзможно с класически бази данни или релационни системи.

## 3. Key Concepts

- **Vector Embeddings** – числови вектори, които представят сложни данни (напр. текст, изображения) в многомерно пространство, където семантичната близост се превръща в геометрическа близост. Мислете за тях като „отпечатъци“ на данните.
- **Nearest Neighbor Search (NNS)** – процесът на намиране на вектори, които са най-близки до даден вектор по определена метрика (например Евклидово разстояние или косинусова близост).
- **Indexing** – изграждане на структури от данни, които ускоряват търсенето, като дървета, хеш таблици или графи. Аналогично на съдържателен указател в книга.
- **Approximate Nearest Neighbor (ANN)** – техники, които позволяват бързо намиране на близки съседи с малка загуба на точност, за сметка на значително по-добра производителност.
- **Scalability** – способността на системата да обработва растящи обеми данни и заявки без значително забавяне.
- **Distributed Architecture** – разпределяне на данни и изчисления върху множество машини за постигане на по-висока производителност и надеждност.
- **Vector Database as a Service (DBaaS)** – облачна услуга, която предоставя готова инфраструктура за работа с векторни данни, като Pinecone.

## 4. Step-by-step Learning Path

1. **Запознайте се с основите на векторните представяния**
   - Фокус: Разберете как текст и изображения се преобразуват във вектори.
   - Задача: Използвайте библиотека като `sentence-transformers` за създаване на текстови embeddings.
   - Въпроси: Какво е embedding? Защо е полезно да се представят данните като вектори?

2. **Изучете принципите на nearest neighbor search**
   - Фокус: Разберете разликата между exact и approximate nearest neighbor.
   - Задача: Реализирайте прост nearest neighbor search с brute force върху малък набор от вектори.
   - Въпроси: Какви са ограниченията на brute force подхода? Какво печелим с ANN?

3. **Инсталирайте и експериментирайте с FAISS**
   - Фокус: Научете как да изградите индекс и да търсите вектори с FAISS.
   - Задача: Индексирайте 10,000 вектора и тествайте търсене на най-близък съседи.
   - Въпроси: Какви типове индекси поддържа FAISS? Как се конфигурира параметърът за компромис между скорост и точност?

4. **Разгледайте Milvus и неговата архитектура**
   - Фокус: Разберете как Milvus поддържа разпределени среди и различни типове индекси.
   - Задача: Инсталирайте Milvus локално или в Docker и импортирайте набор от embeddings.
   - Въпроси: Как Milvus осигурява мащабируемост? Какви са предимствата на разпределената архитектура?

5. **Изследвайте облачни решения като Pinecone**
   - Фокус: Научете как да използвате Pinecone като услуга.
   - Задача: Създайте акаунт в Pinecone, качете embeddings и направете търсене чрез API.
   - Въпроси: Какви са предимствата на DBaaS? Как се управлява инфраструктурата в Pinecone?

6. **Запознайте се с Chroma и интеграцията с LLM**
   - Фокус: Разберете как Chroma улеснява управлението на embeddings в контекста на големи езикови модели.
   - Задача: Инсталирайте Chroma и създайте прост проект за съхранение и търсене на embeddings.
   - Въпроси: Как Chroma се различава от другите решения? Каква е ролята му в AI pipeline?

## 5. Examples

### Пример 1: FAISS – Индексиране и търсене на текстови embeddings

```python
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')
sentences = ["Котка", "Куче", "Мишка", "Лъв", "Тигър"]
embeddings = model.encode(sentences)

d = embeddings.shape[1]
index = faiss.IndexFlatL2(d)  # Евклидово разстояние
index.add(np.array(embeddings, dtype='float32'))

query = model.encode(["Голямо котешко животно"])
D, I = index.search(np.array(query, dtype='float32'), k=2)
print("Най-близки съседи:", [sentences[i] for i in I[0]])
```

### Пример 2: Milvus – Създаване на колекция и търсене (Python SDK)

```python
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection

connections.connect("default", host="localhost", port="19530")

fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=128)
]
schema = CollectionSchema(fields, "Тестова колекция за embeddings")
collection = Collection("test_collection", schema)

import numpy as np
data = [
    [i for i in range(1000)],
    np.random.random((1000, 128)).tolist()
]
collection.insert(data)

collection.load()
search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
results = collection.search(np.random.random((1, 128)).tolist(), "embedding", search_params, limit=3)
print(results)
```

### Пример 3: Pinecone – Качване и търсене на embeddings (Python)

```python
import pinecone
from sentence_transformers import SentenceTransformer

pinecone.init(api_key="YOUR_API_KEY", environment="us-west1-gcp")
index = pinecone.Index("example-index")

model = SentenceTransformer('all-MiniLM-L6-v2')
vectors = model.encode(["apple", "banana", "fruit"])

ids = ["vec1", "vec2", "vec3"]
index.upsert(vectors=list(zip(ids, vectors)))

query_vector = model.encode(["red fruit"])[0]
result = index.query(query_vector, top_k=2)
print(result)
```

## 6. Common Pitfalls

- **Игнориране на мащабируемостта** – започване с brute force търсене при големи набори от данни води до неприемливо забавяне. Използвайте ANN и индекси.
- **Неправилен избор на метрика** – изборът между Евклидово разстояние, косинусова близост и други трябва да съответства на естеството на embeddings.
- **Пренебрегване на качеството на embeddings** – лошо обучени или неподходящи embeddings водят до неефективно търсене.
- **Недостатъчно внимание към конфигурацията на индексите** – параметрите като размер на клъстери, nprobe и др. влияят силно на баланс между скорост и точност.
- **Пренебрегване на инфраструктурните изисквания** – особено при Milvus и други разпределени системи, неправилната конфигурация на хардуера и мрежата може да доведе до нестабилност.
- **Зависимост от един доставчик** – при използване на облачни услуги като Pinecone, трябва да се има предвид vendor lock-in и възможности за миграция.

## 7. Short Retrieval Quiz

1. Какво представлява векторното embedding?
2. Каква е основната цел на nearest neighbor search?
3. Каква е разликата между exact и approximate nearest neighbor?
4. Коя библиотека е оптимизирана за локален бърз ANN – FAISS или Pinecone?
5. Какви са предимствата на разпределена архитектура при Milvus?
6. Какво означава DBaaS в контекста на векторните бази данни?
7. Защо изборът на метрика за разстояние е важен?

## 8. Quick Recap

- Векторните бази данни съхраняват и търсят embeddings, които представят сложни данни в многомерни пространства.
- Търсенето на най-близки съседи е ключова операция за много AI приложения.
- FAISS, Milvus, Chroma и Pinecone предлагат различни решения с различни архитектури и функционалности.
- Индексирането и approximate nearest neighbor алгоритмите са критични за мащабируемост и ефективност.
- Облачните услуги като Pinecone улесняват интеграцията, докато Milvus предлага мощна разпределена платформа.
- Внимателният избор на метрики и параметри на индексите влияе силно на резултатите.
- Практическото експериментиране с реални данни е най-добрият начин за овладяване на темата.

## 9. Spaced Review Plan

| Време след учене | Промпт за преглед                                      |
|-------------------|-------------------------------------------------------|
| 1 ден             | Обяснете какво е vector embedding и nearest neighbor. |
| 3 дни             | Сравнете FAISS и Milvus по архитектура и употреба.    |
| 1 седмица         | Опишете процеса на индексиране и търсене в Pinecone.  |
| 1 месец           | Прегледайте типичните грешки при работа с векторни бази данни и как да ги избегнете. |