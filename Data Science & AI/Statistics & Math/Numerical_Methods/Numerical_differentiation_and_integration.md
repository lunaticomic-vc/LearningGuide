# Numerical_differentiation_and_integration

## 1. Activate Prior Knowledge
- Какво представлява производната на функция и как тя се използва в оптимизацията на машинно обучение?
- Как бихте изчислили площта под кривата на функция, ако нямате аналитична формула?
- В кои случаи числените методи за диференциране и интегриране са по-подходящи от аналитичните?

## 2. Overview
Числената диференциация и интеграция са методи за приближено изчисляване на производни и интеграли, когато аналитичните решения са трудни или невъзможни за намиране. Те са основен инструмент в инженерството, науката за данни и изкуствения интелект, където често работим с дискретни данни или сложни функции.

В контекста на софтуерните системи и AI, числените методи позволяват ефективно моделиране и оптимизация, например при обучение на невронни мрежи или симулации на физични процеси. Те служат като мост между теоретичните модели и реалните данни, осигурявайки точни и бързи изчисления.

Разбирането на тези методи е ключово за разработчици и изследователи, които искат да изграждат надеждни и ефективни алгоритми, особено когато работят с големи обеми данни или сложни модели, където аналитичните решения са непрактични.

## 3. Key Concepts
- **Числена диференциация** – методи за приближено изчисляване на производна на функция, използвайки стойности на функцията в дискретни точки. Може да се представи като „наклон между две точки“.
- **Числена интеграция** – техники за приближено изчисляване на определен интеграл, често чрез сумиране на площи на прости геометрични фигури под кривата.
- **Епсилон (h) в диференциацията** – малко число, което определя разстоянието между точките, използвани за изчисляване на производната; баланс между точност и числена стабилност.
- **Метод на трапеците** – числен метод за интеграция, който апроксимира площта под кривата с трапеци.
- **Метод на Симпсон** – по-точен числен метод за интеграция, който използва параболи за апроксимация на функцията.
- **Грешка на апроксимацията** – разликата между истинската стойност и численото приближение, важна за оценка на точността.
- **Стабилност и условност** – свойства на числените методи, които влияят на надеждността на резултатите при малки промени в данните.

## 4. Step-by-step Learning Path
1. **Разбиране на основите на производната и интеграла**
   - Фокус: Преговор на дефинициите и геометричния смисъл.
   - Задача: Нарисувайте графика на функция и визуализирайте производната и площта под кривата.
   - Въпроси: Какво представлява производната на функция? Как се интерпретира интегралът геометрично?

2. **Изучаване на основните числени методи за диференциация**
   - Фокус: Метод на напредна разлика, назадна разлика и централна разлика.
   - Задача: Имплементирайте на Python функция, която изчислява производна чрез централна разлика.
   - Въпроси: Каква е разликата между напредна и централна разлика? Защо централната разлика е по-точна?

3. **Запознаване с числените методи за интеграция**
   - Фокус: Метод на трапеците и метод на Симпсон.
   - Задача: Напишете код, който изчислява интеграл на функция с метода на трапеците.
   - Въпроси: Как методът на трапеците апроксимира площта? Кога методът на Симпсон е по-подходящ?

4. **Оценка на грешката и стабилността**
   - Фокус: Анализ на грешките и избор на подходящи стъпки (h).
   - Задача: Изследвайте как се променя грешката при различни стойности на h.
   - Въпроси: Как влияе размерът на h на точността? Какво е числено нестабилно изчисление?

5. **Приложения в реални системи**
   - Фокус: Използване на числени методи в машинно обучение и симулации.
   - Задача: Използвайте числена диференциация за изчисляване на градиенти в прост невронен модел.
   - Въпроси: Защо числената диференциация е важна при оптимизация? Как се използва числената интеграция в симулации?

## 5. Examples
### Пример 1: Числена диференциация с централна разлика
```python
def central_difference(f, x, h=1e-5):
    return (f(x + h) - f(x - h)) / (2 * h)

import math
print(central_difference(math.sin, math.pi/4))  # Очаква се около cos(pi/4) ≈ 0.707
```

### Пример 2: Числена интеграция с метода на трапеците
```python
def trapezoidal_rule(f, a, b, n=100):
    h = (b - a) / n
    s = 0.5 * (f(a) + f(b))
    for i in range(1, n):
        s += f(a + i * h)
    return s * h

print(trapezoidal_rule(math.sin, 0, math.pi))  # Очаква се около 2
```

### Пример 3: Изчисляване на градиент в машинно обучение (числена диференциация)
```python
def numerical_gradient(f, x, h=1e-5):
    grad = []
    for i in range(len(x)):
        x_h1 = x.copy()
        x_h2 = x.copy()
        x_h1[i] += h
        x_h2[i] -= h
        grad.append((f(x_h1) - f(x_h2)) / (2 * h))
    return grad

def simple_loss(x):
    return x[0]**2 + x[1]**2

print(numerical_gradient(simple_loss, [3.0, 4.0]))  # Очаква се [6.0, 8.0]
```

## 6. Common Pitfalls
- **Избор на твърде голямо h** – води до неточни приближения и голяма грешка.
- **Избор на твърде малко h** – може да причини числена нестабилност и загуба на точност поради машинно представяне.
- **Игнориране на грешката на апроксимация** – без оценка на грешката, резултатите могат да бъдат подвеждащи.
- **Неправилна имплементация на формулите** – например, объркване на знаците или индекси в разликите.
- **Прилагане на числени методи върху шумни данни без предварителна обработка** – резултатите могат да бъдат неточни и нестабилни.

## 7. Short Retrieval Quiz
1. Какво представлява числената диференциация?
2. Кой метод за числена интеграция използва трапеци?
3. Какво е ролята на параметъра h в числената диференциация?
4. Защо централната разлика е по-точна от напредната разлика?
5. Каква е основната идея зад метода на Симпсон?
6. Как грешката се влияе от размера на стъпката h?
7. Как числените методи се използват в оптимизацията на модели?

## 8. Quick Recap
- Числената диференциация и интеграция са приближени методи за изчисляване на производни и интеграли.
- Те са незаменими при работа с дискретни данни или сложни функции без аналитично решение.
- Основни методи за диференциация са напредна, назадна и централна разлика.
- Методите на трапеците и Симпсон са широко използвани за числена интеграция.
- Изборът на стъпка h е критичен за точността и стабилността на изчисленията.
- Грешката на апроксимацията трябва да се оценява и контролира.
- Числените методи са фундаментални инструменти в AI и инженерни приложения.

## 9. Spaced Review Plan

| Време след първоначално учене | Промпт за преговор                                      |
|-------------------------------|--------------------------------------------------------|
| 1 ден                         | Обяснете с прости думи какво е числена диференциация.  |
| 3 дни                         | Опишете метода на трапеците и кога се използва.        |
| 1 седмица                     | Имплементирайте числена диференциация с централна разлика. |
| 1 месец                      | Дискутирайте влиянието на параметъра h върху точността и стабилността. |