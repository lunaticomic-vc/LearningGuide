# Resampling_methods

## 1. Activate Prior Knowledge
- Какво разбирате под термина "извадково подбиране" (sampling) в контекста на машинното обучение?
- Защо е важно да оценяваме надеждността на моделите, използвайки различни подмножества от данни?
- Как бихте използвали повторно използване на данни, за да подобрите стабилността на прогнози в софтуерна система?

## 2. Overview
Resampling методите са техники, които използват многократно извадково подбиране от наличните данни, за да оценят статистическите характеристики на модели или параметри. Те са особено полезни, когато имаме ограничено количество данни и искаме да разберем колко надеждни са нашите оценки.

В контекста на изкуствения интелект и софтуерното инженерство, resampling позволява да се направи по-обективна оценка на производителността на моделите, като например чрез техники като крос-валидация и бутстреп. Това помага да се избегне пренасищане (overfitting) и да се подобри генерализацията.

Resampling методите са част от по-широката рамка за валидиране и оптимизиране на модели, като осигуряват емпирична основа за вземане на решения при разработка и внедряване на AI системи.

## 3. Key Concepts
- **Bootstrap** – Метод, при който се създават множество нови извадки от оригиналния набор от данни чрез случайно избиране с връщане. Аналогично на това да изтегляте топчета от торба, като след всяко теглене връщате топчето обратно.
- **Cross-validation (Крос-валидация)** – Техника, при която данните се разделят на няколко части (folds), като моделът се обучава върху някои от тях и се тества върху останалите. Това е като да пробвате различни части от пъзел, за да проверите дали цялата картина е вярна.
- **Holdout method** – Прост метод, при който данните се разделят на тренировъчен и тестов набор веднъж. Това е като да имате един учебник и да решавате тест само веднъж.
- **Variance and Bias in Resampling** – Оценка на колко стабилни (variance) и колко точни (bias) са вашите модели при различни извадки от данни.
- **Overfitting** – Когато моделът се научава твърде добре на тренировъчните данни, включително шума, и не се представя добре на нови данни.

## 4. Step-by-step Learning Path
1. **Фокус:** Разберете основната идея на бутстреп метода.  
   **Практическа задача:** Напишете код, който създава 100 бутстреп извадки от малък набор от данни.  
   **Въпроси:** Какво означава "с връщане" при бутстреп? Защо бутстрепът помага при оценка на несигурността?

2. **Фокус:** Изучете крос-валидация (k-fold).  
   **Практическа задача:** Използвайте sklearn или друг инструмент, за да приложите 5-fold крос-валидация на прост регресионен модел.  
   **Въпроси:** Как крос-валидацията помага за избягване на overfitting? Каква е разликата между holdout и крос-валидация?

3. **Фокус:** Анализирайте резултатите от resampling методите.  
   **Практическа задача:** Сравнете средната точност и вариацията на модела, обучен с бутстреп и с крос-валидация.  
   **Въпроси:** Какво показва голяма вариация в оценките? Как да интерпретираме bias и variance?

4. **Фокус:** Прилагане на resampling в реален проект.  
   **Практическа задача:** Използвайте resampling за избор на хиперпараметри в модел на машинно обучение.  
   **Въпроси:** Как resampling подпомага избора на по-стабилен модел? Какви са ограниченията на тези методи?

## 5. Examples

### Пример 1: Bootstrap за оценка на средна стойност
```python
import numpy as np

data = np.array([5, 7, 9, 10, 6])
n_bootstraps = 1000
boot_means = []

for _ in range(n_bootstraps):
    sample = np.random.choice(data, size=len(data), replace=True)
    boot_means.append(np.mean(sample))

print(f"Bootstrap mean estimate: {np.mean(boot_means):.2f}")
print(f"Bootstrap 95% CI: {np.percentile(boot_means, [2.5, 97.5])}")
```

### Пример 2: 5-Fold крос-валидация с sklearn
```python
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

iris = load_iris()
model = LogisticRegression(max_iter=200)
scores = cross_val_score(model, iris.data, iris.target, cv=5)

print(f"Cross-validation scores: {scores}")
print(f"Average accuracy: {scores.mean():.2f}")
```

### Пример 3: Holdout метод
```python
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)
model = DecisionTreeClassifier()
model.fit(X_train, y_train)
print(f"Test accuracy: {model.score(X_test, y_test):.2f}")
```

## 6. Common Pitfalls
- **Използване на бутстреп без достатъчно данни:** При много малки набори от данни бутстреп може да даде подвеждащи оценки, защото извадките са твърде сходни.
- **Неправилно разделяне на данните при крос-валидация:** Например, ако данните не са разбъркани, fold-овете могат да бъдат несбалансирани, което води до изкривени резултати.
- **Изтичане на информация (data leakage):** Ако тестовите данни по някакъв начин влияят на обучението, оценките ще бъдат нереалистично високи.
- **Прекаляване с крос-валидация:** Използването на прекалено много folds може да увеличи времето за обучение без значителни ползи.
- **Игнориране на вариацията:** Оценките на моделите без разглеждане на вариацията могат да доведат до погрешни заключения за стабилността.

## 7. Short Retrieval Quiz
1. Какво представлява бутстреп методът и как се различава от обикновеното извадково подбиране?  
2. Какво е k-fold крос-валидация и защо е полезна?  
3. Каква е основната разлика между holdout метод и крос-валидация?  
4. Как resampling методите помагат за избягване на overfitting?  
5. Какво означава "с връщане" при бутстреп?  
6. Каква е ролята на вариацията в оценката на модел?  
7. Какво е data leakage и защо трябва да се избягва?

## 8. Quick Recap
- Resampling методите използват многократно извадково подбиране за оценка на модели и параметри.  
- Bootstrap създава нови извадки с връщане, позволявайки оценка на несигурността.  
- K-fold крос-валидацията разделя данните на няколко части за по-обективна оценка.  
- Holdout методът е прост, но по-малко надежден от крос-валидацията.  
- Resampling помага да се избегне overfitting и да се подобри генерализацията.  
- Важно е да се избягва data leakage и да се разбира ролята на variance и bias.  
- Практическото прилагане включва избор на модели, хиперпараметри и оценка на стабилност.

## 9. Spaced Review Plan

| Време след учене | Прегледен въпрос / задача                              |
|------------------|-------------------------------------------------------|
| 1 ден            | Обяснете с прости думи какво е bootstrap и защо се използва. |
| 3 дни            | Направете 5-fold крос-валидация на нов набор от данни и интерпретирайте резултатите. |
| 1 седмица        | Сравнете holdout и крос-валидация в контекста на конкретен проект. |
| 1 месец          | Опишете типичните грешки при resampling и как да ги избегнете. |