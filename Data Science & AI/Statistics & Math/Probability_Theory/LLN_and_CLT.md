# LLN_and_CLT

## 1. Activate Prior Knowledge

- Какво знаете за случайните променливи и тяхното поведение при многократни наблюдения?
- Как бихте обяснили защо средната стойност на голям набор от данни често е по-надеждна от отделна наблюдавана стойност?
- В контекста на AI системи, как бихте използвали статистически закони, за да подобрите надеждността на модели, които работят с големи обеми данни?

## 2. Overview

Законът за големите числа (LLN) и централната гранична теорема (CLT) са фундаментални резултати в теорията на вероятностите и статистиката, които описват поведението на средните стойности на случайни променливи при нарастващ брой наблюдения. Те са основата за разбиране на статистическата индукция и оценката на параметри в реални системи.

LLN гарантира, че средната стойност на независими и еднакво разпределени случайни променливи се приближава до очакваната стойност с увеличаване на броя на наблюденията. Това е ключово за стабилността и надеждността на статистически модели и алгоритми, особено в машинното обучение и софтуерната инженерия.

CLT описва как разпределението на нормализираната сума на тези променливи се доближава до нормално разпределение, независимо от първоначалното разпределение на данните. Това позволява използването на нормални модели и доверителни интервали дори при сложни и непредвидими данни.

## 3. Key Concepts

- **Закон за големите числа (LLN)** – При достатъчно голям брой независими и еднакво разпределени наблюдения, средната стойност на тези наблюдения се приближава до истинската очаквана стойност. Аналогия: Колкото повече пъти хвърляте монета, толкова по-близо ще сте до 50% глава.
  
- **Централна гранична теорема (CLT)** – Сумата или средната стойност на голям брой независими случайни променливи с еднакво разпределение се приближава до нормално разпределение, независимо от формата на оригиналното разпределение. Аналогия: Дори ако отделните данни са „шумни“ или „изкривени“, тяхната средна стойност ще изглежда „гладка“ и симетрична.

- **Независими и еднакво разпределени променливи (i.i.d.)** – Ключово условие за LLN и CLT, означава, че всяко наблюдение е статистически независимо от другите и идва от същото разпределение.

- **Очаквана стойност (Expectation)** – Теоретичната средна стойност на случайна променлива, към която се стреми средната на наблюденията.

- **Нормално разпределение (Gaussian distribution)** – Симетрично, камбановидно разпределение, което описва много естествени явления и е резултат от CLT.

## 4. Step-by-step Learning Path

1. **Фокус:** Разберете дефиницията и смисъла на LLN.  
   **Задача:** Симулирайте хвърляне на монета 1000 пъти и изчислете средната стойност на главите.  
   **Въпроси:** Как се променя средната стойност с увеличаване на броя хвърляния? Какво означава това за надеждността на средната?

2. **Фокус:** Изучете CLT и неговото значение.  
   **Задача:** Генерирайте 1000 набора от 30 случайни числа от различни разпределения (например равномерно, експоненциално) и изчислете средната за всеки набор. Постройте хистограма на тези средни.  
   **Въпроси:** Как изглежда разпределението на средните? Какво общо има с нормалното разпределение?

3. **Фокус:** Прилагане на LLN и CLT в AI и софтуерни системи.  
   **Задача:** Имплементирайте функция, която оценява средната грешка на модел върху множество тестови проби и анализира стабилността на оценката с нарастващ брой проби.  
   **Въпроси:** Как LLN помага да се гарантира надеждността на оценката? Как CLT може да бъде използван за изграждане на доверителни интервали?

4. **Фокус:** Разглеждане на ограничения и предпоставки.  
   **Задача:** Анализирайте какво се случва, ако данните не са независими или не са еднакво разпределени.  
   **Въпроси:** Какви са последствията за LLN и CLT? Как бихте адаптирали анализа?

## 5. Examples

### Пример 1: Симулиране на LLN с Python

```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)
coin_flips = np.random.choice([0,1], size=1000)  # 0 = опашка, 1 = глава
cumulative_means = np.cumsum(coin_flips) / np.arange(1, 1001)

plt.plot(cumulative_means)
plt.axhline(0.5, color='red', linestyle='--')
plt.title("Закон за големите числа: средна стойност на хвърляния на монета")
plt.xlabel("Брой хвърляния")
plt.ylabel("Средна стойност на главите")
plt.show()
```

### Пример 2: Демонстрация на CLT с различни разпределения

```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)
sample_size = 30
num_samples = 1000

# Равномерно разпределение
uniform_samples = np.random.uniform(0, 1, (num_samples, sample_size))
uniform_means = uniform_samples.mean(axis=1)

plt.hist(uniform_means, bins=30, density=True)
plt.title("Централна гранична теорема: средни стойности от равномерно разпределение")
plt.xlabel("Средна стойност")
plt.ylabel("Плътност")
plt.show()
```

### Пример 3: Оценка на средна грешка в AI модел

```python
import numpy as np

def model_error(true_values, predictions):
    return np.abs(true_values - predictions)

true = np.random.normal(0, 1, 1000)
pred = true + np.random.normal(0, 0.5, 1000)

errors = model_error(true, pred)
cumulative_mean_error = np.cumsum(errors) / np.arange(1, len(errors)+1)

print(f"Средна грешка след 1000 проби: {cumulative_mean_error[-1]:.4f}")
```

## 6. Common Pitfalls

- **Неспазване на условието за независимост:** Ако данните са зависими (например времеви серии), LLN и CLT може да не важат директно. Решение: използвайте разширени версии или модели, които отчитат зависимостите.

- **Недостатъчно голям брой наблюдения:** При малък брой проби средната стойност може да бъде силно изкривена. Решение: увеличавайте размера на извадката, когато е възможно.

- **Пренебрегване на разпределението на данните:** CLT важи asymptotically; при малки извадки разпределението на средните може да не е нормално. Решение: използвайте непараметрични методи или симулации.

- **Смесване на различни разпределения:** Ако данните не са еднакво разпределени, стандартните версии на LLN и CLT не се прилагат. Решение: анализирайте всяка подгрупа отделно или използвайте обобщени теореми.

## 7. Short Retrieval Quiz

1. Какво гарантира Законът за големите числа?  
2. Какво описва Централната гранична теорема?  
3. Какво означава, че случайните променливи са i.i.d.?  
4. Защо CLT е важна при оценка на параметри в AI?  
5. Какво се случва с разпределението на средните стойности при нарастване на размера на извадката?  
6. Кои са основните предпоставки за приложимостта на LLN и CLT?  
7. Какво е нормално разпределение и как се свързва с CLT?

## 8. Quick Recap

- LLN гарантира, че средната стойност на голям брой i.i.d. случайни променливи се приближава до очакваната стойност.  
- CLT показва, че разпределението на нормализираната сума на тези променливи се доближава до нормално разпределение.  
- И двете теореми са основа за статистическата надеждност и оценка в инженерни и AI системи.  
- Независимостта и еднаквото разпределение са ключови условия за валидността им.  
- Малки извадки и зависими данни могат да нарушат приложимостта на тези теореми.  
- CLT позволява използването на нормални модели и доверителни интервали дори при сложни данни.  
- Практическите приложения включват оценка на модели, анализ на грешки и стабилност на системи.

## 9. Spaced Review Plan

| Време след учене | Промпт за преглед                                      |
|------------------|-------------------------------------------------------|
| 1 ден            | Обяснете с прости думи какво гарантира LLN.           |
| 3 дни            | Дайте пример за прилагане на CLT в AI система.        |
| 1 седмица        | Опишете основните предпоставки за LLN и CLT.          |
| 1 месец          | Анализирайте какви грешки могат да възникнат при неправилна употреба на LLN и CLT. |